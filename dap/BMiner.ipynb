{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T07:12:34.745959Z",
     "start_time": "2020-06-08T07:12:34.740885Z"
    }
   },
   "source": [
    "# Mining Input Grammar from Binaries\n",
    "\n",
    "* Code for subjects [here](#Our-subject-programs)\n",
    "* Evaluation starts [here](#Evaluation)\n",
    "  * The evaluation on specific subjects starts [here](#Subjects)\n",
    "    * [CGIDecode](#CGIDecode)\n",
    "    * [CSVParser](#CSV)\n",
    "    * [URLParse](#URLParse)\n",
    "    * [Json](#Json)\n",
    "    * [INI](#INI)\n",
    "* Results are [here](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:25.027607Z",
     "start_time": "2021-08-20T07:56:21.934270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzingbook in /home/admin1/anaconda3/lib/python3.7/site-packages (0.8.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzingbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:25.042098Z",
     "start_time": "2021-08-20T07:56:25.035729Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our subject programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:25.536245Z",
     "start_time": "2021-08-20T07:56:25.405319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘subjects’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculator.c\n",
    "\n",
    "This is a really simple calculator written in text book recursive descent style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:28.139607Z",
     "start_time": "2021-08-20T07:56:28.134882Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_parse = \"\"\"\\\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <ctype.h>\n",
    "#include \"stdbool.h\"\n",
    "#define MAX_STR_SIZE 10000\n",
    "\n",
    "typedef struct str {\n",
    "  char my_string[MAX_STR_SIZE];\n",
    "  int idx;\n",
    "} my_arg;\n",
    "\n",
    "void parse_num(my_arg *arg);\n",
    "void parse_expr(my_arg *arg);\n",
    "void parse_paren(my_arg *arg);\n",
    "\n",
    "int nesting = 0;\n",
    "\n",
    "void parse_num(my_arg *arg) {\n",
    "    for (;arg->idx < strlen(arg->my_string); arg->idx++) {\n",
    "        if (!isdigit(arg->my_string[arg->idx])) {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    return;\n",
    "}\n",
    "\n",
    "void parse_paren(my_arg *arg) {\n",
    "  if (arg->my_string[arg->idx] != '(') {\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  arg->idx += 1;\n",
    "  parse_expr(arg);\n",
    "  if (arg->my_string[arg->idx] != ')') {\n",
    "    return;\n",
    "  }\n",
    "  arg->idx += 1;\n",
    "}\n",
    "\n",
    "void parse_expr(my_arg *arg) {\n",
    "  while (arg->idx < strlen(arg->my_string)) {\n",
    "    char c = arg->my_string[arg->idx];\n",
    "    if (isdigit(c)) {\n",
    "      parse_num(arg);\n",
    "    } else if (c == '+' || c == '-' || c == '*' || c == '/') {\n",
    "      arg->idx += 1;\n",
    "    } else if (c == '(') {\n",
    "      parse_paren(arg);\n",
    "    } else if (c == ')') {\n",
    "      break;\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    my_arg arg;\n",
    "    strcpy(arg.my_string, argv[1]);\n",
    "    arg.idx = 0;\n",
    "    parse_expr(&arg);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:28.180636Z",
     "start_time": "2021-08-20T07:56:28.175036Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/calc_parse.c', 'w+') as f:\n",
    "    print(calc_parse, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGIDecode.c\n",
    "\n",
    "The CGIDecode is a program to decode a URL encoded string. The source for this program was obtained from [here](https://www.fuzzingbook.org/html/Coverage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:30.860743Z",
     "start_time": "2021-08-20T07:56:30.856787Z"
    }
   },
   "outputs": [],
   "source": [
    "cgi_decode = \"\"\"\\\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "\n",
    "int hex_values[256];\n",
    "\n",
    "\n",
    "int cgi_decode(char *s, char *t) {\n",
    "  for (int i = 0; i < sizeof(hex_values) / sizeof(int); i++) {\n",
    "  hex_values[i] = -1;\n",
    "  }\n",
    "  hex_values['0'] = 0;\n",
    "  hex_values['1'] = 1;\n",
    "  hex_values['2'] = 2;\n",
    "  hex_values['3'] = 3;\n",
    "  hex_values['4'] = 4;\n",
    "  hex_values['5'] = 5;\n",
    "  hex_values['6'] = 6;\n",
    "  hex_values['7'] = 7;\n",
    "  hex_values['8'] = 8;\n",
    "  hex_values['9'] = 9;\n",
    "\n",
    "  hex_values['a'] = 10;\n",
    "  hex_values['b'] = 11;\n",
    "  hex_values['c'] = 12;\n",
    "  hex_values['d'] = 13;\n",
    "  hex_values['e'] = 14;\n",
    "  hex_values['f'] = 15;\n",
    "\n",
    "  hex_values['A'] = 10;\n",
    "  hex_values['B'] = 11;\n",
    "  hex_values['C'] = 12;\n",
    "  hex_values['D'] = 13;\n",
    "  hex_values['E'] = 14;\n",
    "  hex_values['F'] = 15;\n",
    "\n",
    "  while (*s != '\\\\0') {\n",
    "    if (*s == '+') {\n",
    "      *t++ = ' ';\n",
    "    } else if (*s == '%') {\n",
    "      int digit_high = *++s;\n",
    "      int digit_low = *++s;\n",
    "      if (hex_values[digit_high] >= 0 && hex_values[digit_low] >= 0) {\n",
    "        *t++ = hex_values[digit_high] * 16 + hex_values[digit_low];\n",
    "      } else {\n",
    "        return -1;\n",
    "      }\n",
    "    } else {\n",
    "      *t++ = *s;\n",
    "    }\n",
    "    s++;\n",
    "  }\n",
    "  *t = '\\\\0';\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "  char my_string[10240];\n",
    "  char result[10240];\n",
    "  int ret = -1;\n",
    "  \n",
    "  strcpy(my_string, argv[1]);\n",
    "  ret = cgi_decode(my_string, result);\n",
    "  return ret;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:30.903693Z",
     "start_time": "2021-08-20T07:56:30.895139Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/cgi_decode.c', 'w+') as f:\n",
    "    print(cgi_decode, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLParse.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:33.806609Z",
     "start_time": "2021-08-20T07:56:33.802016Z"
    }
   },
   "outputs": [],
   "source": [
    "url_parse = \"\"\"\\\n",
    "/*\n",
    " * urlparse.c\n",
    " *\n",
    " * Decompose a URL into its components.\n",
    " */\n",
    "#include <string.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "enum url_type {\n",
    "    URL_NORMAL,\n",
    "    URL_OLD_TFTP,\n",
    "    URL_PREFIX\n",
    "};\n",
    "\n",
    "struct url_info {\n",
    "    char *scheme;\n",
    "    char *user;\n",
    "    char *passwd;\n",
    "    char *host;\n",
    "    unsigned int port;\n",
    "    char *path;\t\t\t/* Includes query */\n",
    "    enum url_type type;\n",
    "};\n",
    "\n",
    "void parse_url(struct url_info *ui, char *url){\n",
    "    char *p = url;\n",
    "    char *q, *r, *s;\n",
    "\n",
    "    memset(ui, 0, sizeof *ui);\n",
    "\n",
    "    q = strstr(p, \"://\");\n",
    "    if (!q) {\n",
    "        q = strstr(p, \"::\");\n",
    "        if (q) {\n",
    "            *q = '\\\\000';\n",
    "            ui->scheme = \"tftp\";\n",
    "            ui->host = p;\n",
    "            ui->path = q+2;\n",
    "            ui->type = URL_OLD_TFTP;\n",
    "            return;\n",
    "        } else {\n",
    "            ui->path = p;\n",
    "            ui->type = URL_PREFIX;\n",
    "            return;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ui->type = URL_NORMAL;\n",
    "\n",
    "    ui->scheme = p;\n",
    "    *q = '\\\\000';\n",
    "    p = q+3;\n",
    "\n",
    "    q = strchr(p, '/');\n",
    "    if (q) {\n",
    "        *q = '\\\\000';\n",
    "        ui->path = q+1;\n",
    "        q = strchr(q+1, '#');\n",
    "    if (q)\n",
    "        *q = '\\\\000';\n",
    "    } else {\n",
    "        ui->path = \"\";\n",
    "    }\n",
    "\n",
    "    r = strchr(p, '@');\n",
    "    if (r) {\n",
    "        ui->user = p;\n",
    "        *r = '\\\\000';\n",
    "        s = strchr(p, ':');\n",
    "        if (s) {\n",
    "            *s = '\\\\000';\n",
    "            ui->passwd = s+1;\n",
    "        }\n",
    "        p = r+1;\n",
    "    }\n",
    "\n",
    "    ui->host = p;\n",
    "    r = strchr(p, ':');\n",
    "    if (r) {\n",
    "        *r = '\\\\000';\n",
    "        ui->port = atoi(r+1);\n",
    "    }\n",
    "}\n",
    "\n",
    "char *url_escape_unsafe(const char *input){\n",
    "    const char *p = input;\n",
    "    unsigned char c;\n",
    "    char *out, *q;\n",
    "    int n = 0;\n",
    "\n",
    "    while ((c = *p++)) {\n",
    "        if (c < ' ' || c > '~') {\n",
    "            n += 3;\t\t/* Need escaping */\n",
    "        } else {\n",
    "            n++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    q = out = malloc(n+1);\n",
    "    while ((c = *p++)) {\n",
    "        if (c < ' ' || c > '~') {\n",
    "            q += snprintf(q, 3, \"%02X\", c);\n",
    "        } else {\n",
    "            *q++ = c;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    *q = '\\\\000';\n",
    "\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static int hexdigit(char c){\n",
    "    if (c >= '0' && c <= '9')\n",
    "        return c - '0';\n",
    "    c |= 0x20;\n",
    "    if (c >= 'a' && c <= 'f')\n",
    "        return c - 'a' + 10;\n",
    "    return -1;\n",
    "}\n",
    "\n",
    "void url_unescape(char *buffer){\n",
    "    const char *p = buffer;\n",
    "    char *q = buffer;\n",
    "    unsigned char c;\n",
    "    int x, y;\n",
    "\n",
    "    while ((c = *p++)) {\n",
    "        if (c == '%') {\n",
    "            x = hexdigit(p[0]);\n",
    "            if (x >= 0) {\n",
    "                y = hexdigit(p[1]);\n",
    "                if (y >= 0) {\n",
    "                    *q++ = (x << 4) + y;\n",
    "                    p += 2;\n",
    "                    continue;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        *q++ = c;\n",
    "    }\n",
    "    *q = '\\\\000';\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    struct url_info url;\n",
    "    parse_url(&url, argv[1]);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:33.848553Z",
     "start_time": "2021-08-20T07:56:33.840675Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open('subjects/url_parse.c', 'w+') as f:\n",
    "    print(url_parse, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVParser.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:37.506027Z",
     "start_time": "2021-08-20T07:56:37.496906Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_parse = \"\"\"\\\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <stdio.h>\n",
    "#include <errno.h>\n",
    "\n",
    "#ifndef CSVPARSER_H\n",
    "#define CSVPARSER_H\n",
    "\n",
    "#ifdef __cplusplus\n",
    "extern \"C\" {\n",
    "#endif\n",
    "\n",
    "typedef struct CsvRow {\n",
    "    char **fields_;\n",
    "    int numOfFields_;\n",
    "} CsvRow;\n",
    "\n",
    "typedef struct CsvParser {\n",
    "    char *filePath_;\n",
    "    char delimiter_;\n",
    "    int firstLineIsHeader_;\n",
    "    char *errMsg_;\n",
    "    CsvRow *header_;\n",
    "    FILE *fileHandler_;\n",
    "\tint fromString_;\n",
    "\tchar *csvString_;\n",
    "\tint csvStringIter_;\n",
    "} CsvParser;\n",
    "\n",
    "\n",
    "// Public\n",
    "CsvParser *CsvParser_new(const char *filePath, const char *delimiter, int firstLineIsHeader);\n",
    "CsvParser *CsvParser_new_from_string(const char *csvString, const char *delimiter, int firstLineIsHeader);\n",
    "void CsvParser_destroy(CsvParser *csvParser);\n",
    "void CsvParser_destroy_row(CsvRow *csvRow);\n",
    "CsvRow *CsvParser_getHeader(CsvParser *csvParser);\n",
    "CsvRow *CsvParser_getRow(CsvParser *csvParser);\n",
    "int CsvParser_getNumFields(CsvRow *csvRow);\n",
    "char **CsvParser_getFields(CsvRow *csvRow);\n",
    "const char* CsvParser_getErrorMessage(CsvParser *csvParser);\n",
    "\n",
    "// Private\n",
    "CsvRow *_CsvParser_getRow(CsvParser *csvParser);    \n",
    "int _CsvParser_delimiterIsAccepted(const char *delimiter);\n",
    "void _CsvParser_setErrorMessage(CsvParser *csvParser, const char *errorMessage);\n",
    "\n",
    "#ifdef __cplusplus\n",
    "}\n",
    "#endif\n",
    "\n",
    "#endif\n",
    "\n",
    "CsvParser *CsvParser_new(const char *filePath, const char *delimiter, int firstLineIsHeader) {\n",
    "    CsvParser *csvParser = (CsvParser*)malloc(sizeof(CsvParser));\n",
    "    if (filePath == NULL) {\n",
    "        csvParser->filePath_ = NULL;\n",
    "    } else {\n",
    "        int filePathLen = strlen(filePath);\n",
    "        csvParser->filePath_ = (char*)malloc((filePathLen + 1));\n",
    "        strcpy(csvParser->filePath_, filePath);\n",
    "    }\n",
    "    csvParser->firstLineIsHeader_ = firstLineIsHeader;\n",
    "    csvParser->errMsg_ = NULL;\n",
    "    if (delimiter == NULL) {\n",
    "        csvParser->delimiter_ = ',';\n",
    "    } else if (_CsvParser_delimiterIsAccepted(delimiter)) {\n",
    "        csvParser->delimiter_ = *delimiter;\n",
    "    } else {\n",
    "        csvParser->delimiter_ = '\\\\0';\n",
    "    }\n",
    "    csvParser->header_ = NULL;\n",
    "    csvParser->fileHandler_ = NULL;\n",
    "\tcsvParser->fromString_ = 0;\n",
    "\tcsvParser->csvString_ = NULL;\n",
    "\tcsvParser->csvStringIter_ = 0;\n",
    "\n",
    "    return csvParser;\n",
    "}\n",
    "\n",
    "CsvParser *CsvParser_new_from_string(const char *csvString, const char *delimiter, int firstLineIsHeader) {\n",
    "\tCsvParser *csvParser = CsvParser_new(NULL, delimiter, firstLineIsHeader);\n",
    "\tcsvParser->fromString_ = 1;\t\n",
    "\tif (csvString != NULL) {\n",
    "\t\tint csvStringLen = strlen(csvString);\n",
    "\t\tcsvParser->csvString_ = (char*)malloc(csvStringLen + 1);\n",
    "\t\tstrcpy(csvParser->csvString_, csvString);\n",
    "\t}\t\n",
    "\treturn csvParser;\n",
    "}\n",
    "\n",
    "void CsvParser_destroy(CsvParser *csvParser) {\n",
    "    if (csvParser == NULL) {\n",
    "        return;\n",
    "    }\n",
    "    if (csvParser->filePath_ != NULL) {\n",
    "        free(csvParser->filePath_);\n",
    "    }\n",
    "    if (csvParser->errMsg_ != NULL) {\n",
    "        free(csvParser->errMsg_);\n",
    "    }\n",
    "    if (csvParser->fileHandler_ != NULL) {\n",
    "        fclose(csvParser->fileHandler_);\n",
    "    }\n",
    "    if (csvParser->header_ != NULL) {\n",
    "        CsvParser_destroy_row(csvParser->header_);\n",
    "    }\n",
    "\tif (csvParser->csvString_ != NULL) {\n",
    "\t\tfree(csvParser->csvString_);\n",
    "\t}\n",
    "    free(csvParser);\n",
    "}\n",
    "\n",
    "void CsvParser_destroy_row(CsvRow *csvRow) {\n",
    "    int i;\n",
    "    for (i = 0 ; i < csvRow->numOfFields_ ; i++) {\n",
    "        free(csvRow->fields_[i]);\n",
    "    }\n",
    "    free(csvRow);\n",
    "}\n",
    "\n",
    "CsvRow *CsvParser_getHeader(CsvParser *csvParser) {\n",
    "    if (! csvParser->firstLineIsHeader_) {\n",
    "        _CsvParser_setErrorMessage(csvParser, \"Cannot supply header, as current CsvParser object does not support header\");\n",
    "        return NULL;\n",
    "    }\n",
    "    if (csvParser->header_ == NULL) {\n",
    "        csvParser->header_ = _CsvParser_getRow(csvParser);\n",
    "    }\n",
    "    return csvParser->header_;\n",
    "}\n",
    "\n",
    "CsvRow *CsvParser_getRow(CsvParser *csvParser) {\n",
    "    if (csvParser->firstLineIsHeader_ && csvParser->header_ == NULL) {\n",
    "        csvParser->header_ = _CsvParser_getRow(csvParser);\n",
    "    }\n",
    "    return _CsvParser_getRow(csvParser);\n",
    "}\n",
    "\n",
    "int CsvParser_getNumFields(CsvRow *csvRow) {\n",
    "    return csvRow->numOfFields_;\n",
    "}\n",
    "\n",
    "char **CsvParser_getFields(CsvRow *csvRow) {\n",
    "    return csvRow->fields_;\n",
    "}\n",
    "\n",
    "CsvRow *_CsvParser_getRow(CsvParser *csvParser) {\n",
    "    int numRowRealloc = 0;\n",
    "    int acceptedFields = 64;\n",
    "    int acceptedCharsInField = 64;\n",
    "    if (csvParser->filePath_ == NULL && (! csvParser->fromString_)) {\n",
    "        _CsvParser_setErrorMessage(csvParser, \"Supplied CSV file path is NULL\");\n",
    "        return NULL;\n",
    "    }\n",
    "    if (csvParser->csvString_ == NULL && csvParser->fromString_) {\n",
    "        _CsvParser_setErrorMessage(csvParser, \"Supplied CSV string is NULL\");\n",
    "        return NULL;\n",
    "    }\n",
    "    if (csvParser->delimiter_ == '\\\\0') {\n",
    "        _CsvParser_setErrorMessage(csvParser, \"Supplied delimiter is not supported\");\n",
    "        return NULL;\n",
    "    }\n",
    "    if (! csvParser->fromString_) {\n",
    "        if (csvParser->fileHandler_ == NULL) {\n",
    "            csvParser->fileHandler_ = fopen(csvParser->filePath_, \"r\");\n",
    "            if (csvParser->fileHandler_ == NULL) {\n",
    "                int errorNum = errno;\n",
    "                const char *errStr = strerror(errorNum);\n",
    "                char *errMsg = (char*)malloc(1024 + strlen(errStr));\n",
    "                strcpy(errMsg, \"\");\n",
    "                sprintf(errMsg, \"Error opening CSV file for reading: %s : %s\", csvParser->filePath_, errStr);\n",
    "                _CsvParser_setErrorMessage(csvParser, errMsg);\n",
    "                free(errMsg);\n",
    "                return NULL;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    CsvRow *csvRow = (CsvRow*)malloc(sizeof(CsvRow));\n",
    "    csvRow->fields_ = (char**)malloc(acceptedFields * sizeof(char*));\n",
    "    csvRow->numOfFields_ = 0;\n",
    "    int fieldIter = 0;\n",
    "    char *currField = (char*)malloc(acceptedCharsInField);\n",
    "    int inside_complex_field = 0;\n",
    "    int currFieldCharIter = 0;\n",
    "    int seriesOfQuotesLength = 0;\n",
    "    int lastCharIsQuote = 0;\n",
    "    int isEndOfFile = 0;\n",
    "    while (1) {\n",
    "        char currChar = (csvParser->fromString_) ? csvParser->csvString_[csvParser->csvStringIter_] : fgetc(csvParser->fileHandler_);\n",
    "        csvParser->csvStringIter_++;\n",
    "        int endOfFileIndicator;\n",
    "        if (csvParser->fromString_) {\n",
    "            endOfFileIndicator = (currChar == '\\\\0');\n",
    "        } else {\n",
    "            endOfFileIndicator = feof(csvParser->fileHandler_);\n",
    "        }\n",
    "        if (endOfFileIndicator) {\n",
    "            if (currFieldCharIter == 0 && fieldIter == 0) {\n",
    "                _CsvParser_setErrorMessage(csvParser, \"Reached EOF\");\n",
    "                return NULL;\n",
    "            }\n",
    "            currChar = '\\\\n';\n",
    "            isEndOfFile = 1;\n",
    "        }\n",
    "        if (currChar == '\\\\r') {\n",
    "            continue;\n",
    "        }\n",
    "        if (currFieldCharIter == 0  && ! lastCharIsQuote) {\n",
    "            if (currChar == '\\\\\"') {\n",
    "                inside_complex_field = 1;\n",
    "                lastCharIsQuote = 1;\n",
    "                continue;\n",
    "            }\n",
    "        } else if (currChar == '\\\\\"') {\n",
    "            seriesOfQuotesLength++;\n",
    "            inside_complex_field = (seriesOfQuotesLength % 2 == 0);\n",
    "            if (inside_complex_field) {\n",
    "                currFieldCharIter--;\n",
    "            }\n",
    "        } else {\n",
    "            seriesOfQuotesLength = 0;\n",
    "        }\n",
    "        if (isEndOfFile || ((currChar == csvParser->delimiter_ || currChar == '\\\\n') && ! inside_complex_field) ){\n",
    "            currField[lastCharIsQuote ? currFieldCharIter - 1 : currFieldCharIter] = '\\\\0';\n",
    "            csvRow->fields_[fieldIter] = (char*)malloc(currFieldCharIter + 1);\n",
    "            strcpy(csvRow->fields_[fieldIter], currField);\n",
    "            free(currField);\n",
    "            csvRow->numOfFields_++;\n",
    "            if (currChar == '\\\\n') {\n",
    "                return csvRow;\n",
    "            }\n",
    "            if (csvRow->numOfFields_ != 0 && csvRow->numOfFields_ % acceptedFields == 0) {\n",
    "                csvRow->fields_ = (char**)realloc(csvRow->fields_, ((numRowRealloc + 2) * acceptedFields) * sizeof(char*));\n",
    "                numRowRealloc++;\n",
    "            }\n",
    "            acceptedCharsInField = 64;\n",
    "            currField = (char*)malloc(acceptedCharsInField);\n",
    "            currFieldCharIter = 0;\n",
    "            fieldIter++;\n",
    "            inside_complex_field = 0;\n",
    "        } else {\n",
    "            currField[currFieldCharIter] = currChar;\n",
    "            currFieldCharIter++;\n",
    "            if (currFieldCharIter == acceptedCharsInField - 1) {\n",
    "                acceptedCharsInField *= 2;\n",
    "                currField = (char*)realloc(currField, acceptedCharsInField);\n",
    "            }\n",
    "        }\n",
    "        lastCharIsQuote = (currChar == '\\\\\"') ? 1 : 0;\n",
    "    }\n",
    "}\n",
    "\n",
    "int _CsvParser_delimiterIsAccepted(const char *delimiter) {\n",
    "    char actualDelimiter = *delimiter;\n",
    "    if (actualDelimiter == '\\\\n' || actualDelimiter == '\\\\r' || actualDelimiter == '\\\\0' ||\n",
    "            actualDelimiter == '\\\\\"') {\n",
    "        return 0;\n",
    "    }\n",
    "    return 1;\n",
    "}\n",
    "\n",
    "void _CsvParser_setErrorMessage(CsvParser *csvParser, const char *errorMessage) {\n",
    "    if (csvParser->errMsg_ != NULL) {\n",
    "        free(csvParser->errMsg_);\n",
    "    }\n",
    "    int errMsgLen = strlen(errorMessage);\n",
    "    csvParser->errMsg_ = (char*)malloc(errMsgLen + 1);\n",
    "    strcpy(csvParser->errMsg_, errorMessage);\n",
    "}\n",
    "\n",
    "const char *CsvParser_getErrorMessage(CsvParser *csvParser) {\n",
    "    return csvParser->errMsg_;\n",
    "}\n",
    "\n",
    "\n",
    "// newly added for running the code\n",
    "char* read_input() {\n",
    "    int counter = 0;\n",
    "    char* chars = malloc(sizeof(char) * 1000);\n",
    "    char c = 0;\n",
    "    while((c = fgetc(stdin)) != EOF){\n",
    "        if (counter == 1000) {\n",
    "            exit(1);\n",
    "        }\n",
    "        chars[counter++] = c;\n",
    "    }\n",
    "    chars[counter] = '\\\\0';\n",
    "    return chars;\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    char myString[10000];\n",
    "    strcpy(myString, argv[1]);\n",
    "    CsvParser *csvparser = CsvParser_new_from_string(myString, NULL, 1);\n",
    "    CsvRow *header;\n",
    "    CsvRow *row;\n",
    "    int i;\n",
    "\n",
    "    header = CsvParser_getHeader(csvparser);\n",
    "    if (header == NULL) {\n",
    "        printf(\"%s\\\\n\", CsvParser_getErrorMessage(csvparser));\n",
    "        return 1;\n",
    "    }\n",
    "    char **headerFields = CsvParser_getFields(header);\n",
    "    for (i = 0 ; i < CsvParser_getNumFields(header) ; i++) {\n",
    "        printf(\"TITLE: %s\\\\n\", headerFields[i]);\n",
    "    }\n",
    "    while ((row = CsvParser_getRow(csvparser)) ) {\n",
    "        printf(\"NEW LINE:\\\\n\");\n",
    "        char **rowFields = CsvParser_getFields(row);\n",
    "        for (i = 0 ; i < CsvParser_getNumFields(row) ; i++) {\n",
    "            printf(\"FIELD: %s\\\\n\", rowFields[i]);\n",
    "        }\n",
    "        CsvParser_destroy_row(row);\n",
    "    }\n",
    "    CsvParser_destroy(csvparser);\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "#ifdef __cplusplus\n",
    "}\n",
    "#endif\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:37.550569Z",
     "start_time": "2021-08-20T07:56:37.540558Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/csvparser.c', 'w+') as f:\n",
    "    print(csv_parse, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIParser.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:40.402652Z",
     "start_time": "2021-08-20T07:56:40.392545Z"
    }
   },
   "outputs": [],
   "source": [
    "ini_parse = \"\"\"\\\n",
    "/* inih -- simple .INI file parser\n",
    "\n",
    "inih is released under the New BSD license (see LICENSE.txt). Go to the project\n",
    "home page for more info:\n",
    "\n",
    "https://github.com/benhoyt/inih\n",
    "\n",
    "*/\n",
    "\n",
    "#ifndef __INI_H__\n",
    "#define __INI_H__\n",
    "\n",
    "/* Make this header file easier to include in C++ code */\n",
    "#ifdef __cplusplus\n",
    "extern \"C\" {\n",
    "#endif\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "/* Nonzero if ini_handler callback should accept lineno parameter. */\n",
    "#ifndef INI_HANDLER_LINENO\n",
    "#define INI_HANDLER_LINENO 0\n",
    "#endif\n",
    "\n",
    "/* Typedef for prototype of handler function. */\n",
    "#if INI_HANDLER_LINENO\n",
    "typedef int (*ini_handler)(void* user, const char* section,\n",
    "                           const char* name, const char* value,\n",
    "                           int lineno);\n",
    "#else\n",
    "typedef int (*ini_handler)(void* user, const char* section,\n",
    "                           const char* name, const char* value);\n",
    "#endif\n",
    "\n",
    "/* Typedef for prototype of fgets-style reader function. */\n",
    "typedef char* (*ini_reader)(char* str, int num, void* stream);\n",
    "\n",
    "/* Parse given INI-style file. May have [section]s, name=value pairs\n",
    "   (whitespace stripped), and comments starting with ';' (semicolon). Section\n",
    "   is \"\" if name=value pair parsed before any section heading. name:value\n",
    "   pairs are also supported as a concession to Python's configparser.\n",
    "\n",
    "   For each name=value pair parsed, call handler function with given user\n",
    "   pointer as well as section, name, and value (data only valid for duration\n",
    "   of handler call). Handler should return nonzero on success, zero on error.\n",
    "\n",
    "   Returns 0 on success, line number of first error on parse error (doesn't\n",
    "   stop on first error), -1 on file open error, or -2 on memory allocation\n",
    "   error (only when INI_USE_STACK is zero).\n",
    "*/\n",
    "int ini_parse(const char* filename, ini_handler handler, void* user);\n",
    "\n",
    "/* Same as ini_parse(), but takes a FILE* instead of filename. This doesn't\n",
    "   close the file when it's finished -- the caller must do that. */\n",
    "int ini_parse_file(FILE* file, ini_handler handler, void* user);\n",
    "\n",
    "/* Same as ini_parse(), but takes an ini_reader function pointer instead of\n",
    "   filename. Used for implementing custom or string-based I/O (see also\n",
    "   ini_parse_string). */\n",
    "int ini_parse_stream(ini_reader reader, void* stream, ini_handler handler,\n",
    "                     void* user);\n",
    "\n",
    "/* Same as ini_parse(), but takes a zero-terminated string with the INI data\n",
    "instead of a file. Useful for parsing INI data from a network socket or\n",
    "already in memory. */\n",
    "int ini_parse_string(const char* string, ini_handler handler, void* user);\n",
    "\n",
    "/* Nonzero to allow multi-line value parsing, in the style of Python's\n",
    "   configparser. If allowed, ini_parse() will call the handler with the same\n",
    "   name for each subsequent line parsed. */\n",
    "#ifndef INI_ALLOW_MULTILINE\n",
    "#define INI_ALLOW_MULTILINE 1\n",
    "#endif\n",
    "\n",
    "/* Nonzero to allow a UTF-8 BOM sequence (0xEF 0xBB 0xBF) at the start of\n",
    "   the file. See https://github.com/benhoyt/inih/issues/21 */\n",
    "#ifndef INI_ALLOW_BOM\n",
    "#define INI_ALLOW_BOM 1\n",
    "#endif\n",
    "\n",
    "/* Chars that begin a start-of-line comment. Per Python configparser, allow\n",
    "   both ; and # comments at the start of a line by default. */\n",
    "#ifndef INI_START_COMMENT_PREFIXES\n",
    "#define INI_START_COMMENT_PREFIXES \";#\"\n",
    "#endif\n",
    "\n",
    "/* Nonzero to allow inline comments (with valid inline comment characters\n",
    "   specified by INI_INLINE_COMMENT_PREFIXES). Set to 0 to turn off and match\n",
    "   Python 3.2+ configparser behaviour. */\n",
    "#ifndef INI_ALLOW_INLINE_COMMENTS\n",
    "#define INI_ALLOW_INLINE_COMMENTS 1\n",
    "#endif\n",
    "#ifndef INI_INLINE_COMMENT_PREFIXES\n",
    "#define INI_INLINE_COMMENT_PREFIXES \";\"\n",
    "#endif\n",
    "\n",
    "/* Nonzero to use stack for line buffer, zero to use heap (malloc/free). */\n",
    "#ifndef INI_USE_STACK\n",
    "#define INI_USE_STACK 1\n",
    "#endif\n",
    "\n",
    "/* Maximum line length for any line in INI file (stack or heap). Note that\n",
    "   this must be 3 more than the longest line (due to '\\\\r', '\\\\n', and '\\\\0'). */\n",
    "#ifndef INI_MAX_LINE\n",
    "#define INI_MAX_LINE 200\n",
    "#endif\n",
    "\n",
    "/* Nonzero to allow heap line buffer to grow via realloc(), zero for a\n",
    "   fixed-size buffer of INI_MAX_LINE bytes. Only applies if INI_USE_STACK is\n",
    "   zero. */\n",
    "#ifndef INI_ALLOW_REALLOC\n",
    "#define INI_ALLOW_REALLOC 0\n",
    "#endif\n",
    "\n",
    "/* Initial size in bytes for heap line buffer. Only applies if INI_USE_STACK\n",
    "   is zero. */\n",
    "#ifndef INI_INITIAL_ALLOC\n",
    "#define INI_INITIAL_ALLOC 200\n",
    "#endif\n",
    "\n",
    "/* Stop parsing on first error (default is to keep parsing). */\n",
    "#ifndef INI_STOP_ON_FIRST_ERROR\n",
    "#define INI_STOP_ON_FIRST_ERROR 1\n",
    "#endif\n",
    "\n",
    "#ifdef __cplusplus\n",
    "}\n",
    "#endif\n",
    "\n",
    "#endif /* __INI_H__ */\n",
    "\n",
    "\n",
    "/* inih -- simple .INI file parser\n",
    "\n",
    "inih is released under the New BSD license (see LICENSE.txt). Go to the project\n",
    "home page for more info:\n",
    "\n",
    "https://github.com/benhoyt/inih\n",
    "\n",
    "*/\n",
    "\n",
    "#if defined(_MSC_VER) && !defined(_CRT_SECURE_NO_WARNINGS)\n",
    "#define _CRT_SECURE_NO_WARNINGS\n",
    "#endif\n",
    "\n",
    "// #include <stdio.h>\n",
    "#include <ctype.h>\n",
    "#include <string.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "// #include \"ini.h\"\n",
    "\n",
    "#if !INI_USE_STACK\n",
    "#include <stdlib.h>\n",
    "#endif\n",
    "\n",
    "#define MAX_SECTION 50\n",
    "#define MAX_NAME 50\n",
    "\n",
    "/* Used by ini_parse_string() to keep track of string parsing state. */\n",
    "typedef struct {\n",
    "    const char* ptr;\n",
    "    size_t num_left;\n",
    "} ini_parse_string_ctx;\n",
    "\n",
    "/* Strip whitespace chars off end of given string, in place. Return s. */\n",
    "static char* rstrip(char* s)\n",
    "{\n",
    "    char* p = s + strlen(s);\n",
    "    while (p > s && isspace((unsigned char)(*--p)))\n",
    "        *p = '\\\\0';\n",
    "    return s;\n",
    "}\n",
    "\n",
    "/* Return pointer to first non-whitespace char in given string. */\n",
    "static char* lskip(const char* s)\n",
    "{\n",
    "    while (*s && isspace((unsigned char)(*s)))\n",
    "        s++;\n",
    "    return (char*)s;\n",
    "}\n",
    "\n",
    "/* Return pointer to first char (of chars) or inline comment in given string,\n",
    "   or pointer to null at end of string if neither found. Inline comment must\n",
    "   be prefixed by a whitespace character to register as a comment. */\n",
    "static char* find_chars_or_comment(const char* s, const char* chars)\n",
    "{\n",
    "#if INI_ALLOW_INLINE_COMMENTS\n",
    "    int was_space = 0;\n",
    "    while (*s && (!chars || !strchr(chars, *s)) &&\n",
    "           !(was_space && strchr(INI_INLINE_COMMENT_PREFIXES, *s))) {\n",
    "        was_space = isspace((unsigned char)(*s));\n",
    "        s++;\n",
    "    }\n",
    "#else\n",
    "    while (*s && (!chars || !strchr(chars, *s))) {\n",
    "        s++;\n",
    "    }\n",
    "#endif\n",
    "    return (char*)s;\n",
    "}\n",
    "\n",
    "/* Version of strncpy that ensures dest (size bytes) is null-terminated. */\n",
    "static char* strncpy0(char* dest, const char* src, size_t size)\n",
    "{\n",
    "    strncpy(dest, src, size - 1);\n",
    "    dest[size - 1] = '\\\\0';\n",
    "    return dest;\n",
    "}\n",
    "\n",
    "/* See documentation in header file. */\n",
    "int ini_parse_stream(ini_reader reader, void* stream, ini_handler handler,\n",
    "                     void* user)\n",
    "{\n",
    "    /* Uses a fair bit of stack (use heap instead if you need to) */\n",
    "#if INI_USE_STACK\n",
    "    char line[INI_MAX_LINE];\n",
    "    int max_line = INI_MAX_LINE;\n",
    "#else\n",
    "    char* line;\n",
    "    int max_line = INI_INITIAL_ALLOC;\n",
    "#endif\n",
    "#if INI_ALLOW_REALLOC && !INI_USE_STACK\n",
    "    char* new_line;\n",
    "    int offset;\n",
    "#endif\n",
    "    char section[MAX_SECTION] = \"\";\n",
    "    char prev_name[MAX_NAME] = \"\";\n",
    "\n",
    "    char* start;\n",
    "    char* end;\n",
    "    char* name;\n",
    "    char* value;\n",
    "    int lineno = 0;\n",
    "    int error = 0;\n",
    "\n",
    "#if !INI_USE_STACK\n",
    "    line = (char*)malloc(INI_INITIAL_ALLOC);\n",
    "    if (!line) {\n",
    "        return -2;\n",
    "    }\n",
    "#endif\n",
    "\n",
    "#if INI_HANDLER_LINENO\n",
    "#define HANDLER(u, s, n, v) handler(u, s, n, v, lineno)\n",
    "#else\n",
    "#define HANDLER(u, s, n, v) handler(u, s, n, v)\n",
    "#endif\n",
    "\n",
    "    /* Scan through stream line by line */\n",
    "    while (reader(line, max_line, stream) != NULL) {\n",
    "#if INI_ALLOW_REALLOC && !INI_USE_STACK\n",
    "        offset = strlen(line);\n",
    "        while (offset == max_line - 1 && line[offset - 1] != '\\\\n') {\n",
    "            max_line *= 2;\n",
    "            if (max_line > INI_MAX_LINE)\n",
    "                max_line = INI_MAX_LINE;\n",
    "            new_line = realloc(line, max_line);\n",
    "            if (!new_line) {\n",
    "                free(line);\n",
    "                return -2;\n",
    "            }\n",
    "            line = new_line;\n",
    "            if (reader(line + offset, max_line - offset, stream) == NULL)\n",
    "                break;\n",
    "            if (max_line >= INI_MAX_LINE)\n",
    "                break;\n",
    "            offset += strlen(line + offset);\n",
    "        }\n",
    "#endif\n",
    "\n",
    "        lineno++;\n",
    "\n",
    "        start = line;\n",
    "#if INI_ALLOW_BOM\n",
    "        if (lineno == 1 && (unsigned char)start[0] == 0xEF &&\n",
    "                           (unsigned char)start[1] == 0xBB &&\n",
    "                           (unsigned char)start[2] == 0xBF) {\n",
    "            start += 3;\n",
    "        }\n",
    "#endif\n",
    "        start = lskip(rstrip(start));\n",
    "\n",
    "        if (strchr(INI_START_COMMENT_PREFIXES, *start)) {\n",
    "            /* Start-of-line comment */\n",
    "        }\n",
    "#if INI_ALLOW_MULTILINE\n",
    "        else if (*prev_name && *start && start > line) {\n",
    "            /* Non-blank line with leading whitespace, treat as continuation\n",
    "               of previous name's value (as per Python configparser). */\n",
    "            if (!HANDLER(user, section, prev_name, start) && !error)\n",
    "                error = lineno;\n",
    "        }\n",
    "#endif\n",
    "        else if (*start == '[') {\n",
    "            /* A \"[section]\" line */\n",
    "            end = find_chars_or_comment(start + 1, \"]\");\n",
    "            if (*end == ']') {\n",
    "                *end = '\\\\0';\n",
    "                strncpy0(section, start + 1, sizeof(section));\n",
    "                *prev_name = '\\\\0';\n",
    "            }\n",
    "            else if (!error) {\n",
    "                /* No ']' found on section line */\n",
    "                error = lineno;\n",
    "            }\n",
    "        }\n",
    "        else if (*start) {\n",
    "            /* Not a comment, must be a name[=:]value pair */\n",
    "            end = find_chars_or_comment(start, \"=:\");\n",
    "            if (*end == '=' || *end == ':') {\n",
    "                *end = '\\\\0';\n",
    "                name = rstrip(start);\n",
    "                value = end + 1;\n",
    "#if INI_ALLOW_INLINE_COMMENTS\n",
    "                end = find_chars_or_comment(value, NULL);\n",
    "                if (*end)\n",
    "                    *end = '\\\\0';\n",
    "#endif\n",
    "                value = lskip(value);\n",
    "                rstrip(value);\n",
    "\n",
    "                /* Valid name[=:]value pair found, call handler */\n",
    "                strncpy0(prev_name, name, sizeof(prev_name));\n",
    "                if (!HANDLER(user, section, name, value) && !error)\n",
    "                    error = lineno;\n",
    "            }\n",
    "            else if (!error) {\n",
    "                /* No '=' or ':' found on name[=:]value line */\n",
    "                error = lineno;\n",
    "            }\n",
    "        }\n",
    "\n",
    "#if INI_STOP_ON_FIRST_ERROR\n",
    "        if (error)\n",
    "            break;\n",
    "#endif\n",
    "    }\n",
    "\n",
    "#if !INI_USE_STACK\n",
    "    free(line);\n",
    "#endif\n",
    "\n",
    "    return error;\n",
    "}\n",
    "\n",
    "/* See documentation in header file. */\n",
    "int ini_parse_file(FILE* file, ini_handler handler, void* user)\n",
    "{\n",
    "    return ini_parse_stream((ini_reader)fgets, file, handler, user);\n",
    "}\n",
    "\n",
    "/* See documentation in header file. */\n",
    "int ini_parse(const char* filename, ini_handler handler, void* user)\n",
    "{\n",
    "    FILE* file;\n",
    "    int error;\n",
    "\n",
    "    file = fopen(filename, \"r\");\n",
    "    if (!file)\n",
    "        return -1;\n",
    "    error = ini_parse_file(file, handler, user);\n",
    "    fclose(file);\n",
    "    return error;\n",
    "}\n",
    "\n",
    "/* An ini_reader function to read the next line from a string buffer. This\n",
    "   is the fgets() equivalent used by ini_parse_string(). */\n",
    "static char* ini_reader_string(char* str, int num, void* stream) {\n",
    "    ini_parse_string_ctx* ctx = (ini_parse_string_ctx*)stream;\n",
    "    const char* ctx_ptr = ctx->ptr;\n",
    "    size_t ctx_num_left = ctx->num_left;\n",
    "    char* strp = str;\n",
    "    char c;\n",
    "\n",
    "    if (ctx_num_left == 0 || num < 2)\n",
    "        return NULL;\n",
    "\n",
    "    while (num > 1 && ctx_num_left != 0) {\n",
    "        c = *ctx_ptr++;\n",
    "        ctx_num_left--;\n",
    "        *strp++ = c;\n",
    "        if (c == '\\\\n')\n",
    "            break;\n",
    "        num--;\n",
    "    }\n",
    "\n",
    "    *strp = '\\\\0';\n",
    "    ctx->ptr = ctx_ptr;\n",
    "    ctx->num_left = ctx_num_left;\n",
    "    return str;\n",
    "}\n",
    "\n",
    "/* See documentation in header file. */\n",
    "int ini_parse_string(const char* string, ini_handler handler, void* user) {\n",
    "    ini_parse_string_ctx ctx;\n",
    "\n",
    "    ctx.ptr = string;\n",
    "    ctx.num_left = strlen(string);\n",
    "    return ini_parse_stream((ini_reader)ini_reader_string, &ctx, handler,\n",
    "                            user);\n",
    "}\n",
    "\n",
    "// newly added for running the code\n",
    "typedef struct\n",
    "{\n",
    "    int empty;\n",
    "} configuration;\n",
    "\n",
    "// took the example from the README file to have sth. to parse\n",
    "static int handler(void* user, const char* section, const char* name,\n",
    "                   const char* value)\n",
    "{\n",
    "    return 1;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    configuration config;\n",
    "    return ini_parse_string(argv[1], handler, &config);\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:40.436272Z",
     "start_time": "2021-08-20T07:56:40.432003Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open('subjects/ini.c', 'w+') as f:\n",
    "    print(ini_parse, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.074892Z",
     "start_time": "2021-08-20T07:56:43.069322Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_h = \"\"\"\\\n",
    "#ifndef HS_VECTOR_H\n",
    "#define HS_VECTOR_H\n",
    "\n",
    "#include <stddef.h>\n",
    "\n",
    "typedef struct {\n",
    "    size_t capacity;\n",
    "    size_t data_size;\n",
    "    size_t size;\n",
    "    char* data;\n",
    "} vector;\n",
    "\n",
    "void vector_init(vector* v, size_t data_size);\n",
    "\n",
    "void vector_free(vector* v);\n",
    "\n",
    "void* vector_get(const vector* v, size_t index);\n",
    "\n",
    "void* vector_get_checked(const vector* v, size_t index);\n",
    "\n",
    "void vector_reserve(vector* v, size_t new_capacity);\n",
    "\n",
    "void vector_push_back(vector* v, void* data);\n",
    "\n",
    "\n",
    "typedef void(*vector_foreach_t)(void*);\n",
    "\n",
    "void vector_foreach(const vector* v, vector_foreach_t fp);\n",
    "\n",
    "typedef int(*vector_foreach_data_t)(void*, void*);\n",
    "\n",
    "void vector_foreach_data(const vector* v, vector_foreach_data_t fp, void* data);\n",
    "\n",
    "#ifdef BUILD_TEST\n",
    "void vector_test_all();\n",
    "#endif\n",
    "\n",
    "#endif\n",
    "\n",
    "\n",
    "#ifndef HS_JSON_H\n",
    "#define HS_JSON_H\n",
    "\n",
    "#define BUFFER 10240\n",
    "\n",
    "/*\n",
    "enum json_value_type {\n",
    "\tTYPE_NULL,\n",
    "\tTYPE_BOOL,\n",
    "\tTYPE_NUMBER,\n",
    "\tTYPE_OBJECT, // Is a vector with pairwise entries, key, value\n",
    "\tTYPE_ARRAY, // Is a vector, all entries are plain \n",
    "\tTYPE_STRING,\n",
    "\tTYPE_KEY\n",
    "};*/\n",
    "\n",
    "typedef struct {\n",
    "\tint type;\n",
    "\tunion {\n",
    "\t\tint boolean;\n",
    "\t\tdouble number;\n",
    "\t\tchar* string;\n",
    "\t\tchar* key;\n",
    "\t\tvector array;\n",
    "\t\tvector object;\n",
    "\t} value;\n",
    "} json_value;\n",
    "\n",
    "// Parse string into structure of json elements and values\n",
    "// return 1 if successful.\n",
    "int json_parse(const char* input, json_value* root);\n",
    "\n",
    "// Free the structure and all the allocated values\n",
    "void json_free_value(json_value* val);\n",
    "\n",
    "// Convert value to string if possible, asserts if not\n",
    "char* json_value_to_string(json_value* value);\n",
    "\n",
    "// Convert value to double if possible asserts if not\n",
    "double json_value_to_double(json_value* value);\n",
    "\n",
    "// Convert value to bool if possible asserts if not\n",
    "int json_value_to_bool(json_value* value);\n",
    "\n",
    "// Convert value to vector if it's an array asserts if not\n",
    "vector* json_value_to_array(json_value* value);\n",
    "\n",
    "// Convert value to vector if it's an object, asserts if not\n",
    "vector* json_value_to_object(json_value* value);\n",
    "\n",
    "// Fetch the value with given index from root, asserts if root is not array\n",
    "json_value* json_value_at(const json_value* root, size_t index);\n",
    "\n",
    "// Fetche the value with the given key from root, asserts if root is not object\n",
    "json_value * json_value_with_key(const json_value * root, const char * key);\n",
    "\n",
    "#endif\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.116810Z",
     "start_time": "2021-08-20T07:56:43.105744Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/vector.h', 'w+') as f:\n",
    "    print(vector_h, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.158142Z",
     "start_time": "2021-08-20T07:56:43.150480Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_c = \"\"\"\\\n",
    "#include \"vector.h\"\n",
    "\n",
    "#include <assert.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "// Allocate the data structure for the vector\n",
    "void vector_init(vector* v, size_t data_size) {\n",
    "\tif (v == NULL) return;\n",
    "\t\n",
    "\tv->data = malloc(data_size);\n",
    "\tif (v->data != NULL)\n",
    "\t{\n",
    "\t\tv->capacity = 1;\n",
    "        v->data_size = data_size;\n",
    "        v->size = 0; \n",
    "\t}\n",
    "}\n",
    "\n",
    "// Free the memory of the vector, the pointer to the vector is invalid after this\n",
    "void vector_free(vector* v)\n",
    "{\n",
    "    if (v)\n",
    "    {\n",
    "        free(v->data);\n",
    "\t\tv->data = NULL;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Return the element at index, does not do a range check\n",
    "void* vector_get(const vector* v, size_t index) {\n",
    "\treturn &(v->data[index * v->data_size]);\n",
    "}\n",
    "\n",
    "// Return the element at index, return NULL if index is out of range for the vector\n",
    "void* vector_get_checked(const vector* v, size_t index) {\n",
    "\treturn (index < v->size) ? &(v->data[index * v->data_size]) : NULL;\n",
    "}\n",
    "\n",
    "// if capacity < new_capacity realloc up to new_capacity\n",
    "void vector_reserve(vector* v, size_t new_capacity) {\n",
    "\tif (new_capacity <= v->capacity) return;\n",
    "    void* new_data = realloc(v->data, new_capacity*v->data_size);\n",
    "    if (new_data) {\n",
    "        v->capacity = new_capacity;\n",
    "        v->data = new_data;\n",
    "    }\n",
    "    else {\n",
    "        abort();\n",
    "    }\n",
    "}\n",
    "\n",
    "// Puts an element data[size * data_size], will reserve more space if size == capacity\n",
    "void vector_push_back(vector* v, void* data) {\n",
    "    if (v->size >= v->capacity) {\n",
    "\t\tsize_t new_capacity = (v->capacity > 0) ? (size_t)(v->capacity * 2) : 1;\n",
    "\t\tvector_reserve(v, new_capacity);\n",
    "    }\n",
    "    memcpy(vector_get(v,v->size), data, v->data_size);\n",
    "    ++v->size;\n",
    "}\n",
    "\n",
    "void vector_foreach_data(const vector* v, vector_foreach_data_t fp, void* data)\n",
    "{\n",
    "\tif (v == NULL) return;\n",
    "\tchar* item = v->data;\n",
    "\tassert(item != NULL);\n",
    "\tfor (size_t i = 0; i < v->size; i++) {\n",
    "\t\tif (! fp(item, (void *)data)) break;\n",
    "\t\titem += v->data_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "void vector_foreach(const vector* v, vector_foreach_t fp)\n",
    "{\n",
    "\tif (v == NULL) return;\n",
    "\tchar* item = v->data;\n",
    "\tassert(item != NULL);\n",
    "\tfor (size_t i = 0; i < v->size; i++) {\n",
    "\t\tfp(item);\n",
    "\t\titem += v->data_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "#ifdef BUILD_TEST\n",
    "\n",
    "void vector_test_alloc_free(void)\n",
    "{\n",
    "\tprintf(\"vector_test_alloc_free: \");\n",
    "\tvector v; \n",
    "\tvector_init(&v, sizeof(int));\n",
    "    assert(v.capacity == 1);\n",
    "    assert(v.size == 0);\n",
    "    assert(v.data_size == sizeof(int));\n",
    "    assert(v.data != NULL);\n",
    "\tprintf(\"OK\\\\n\");\n",
    "    vector_free(&v);\n",
    "}\n",
    "\n",
    "void vector_test_insert_read_int(void)\n",
    "{\n",
    "\tprintf(\"vector_test_insert_read_int: \");\n",
    "\tint val1 = 0xabcdabcd;\n",
    "\tint val2 = 0xeffeeffe;\n",
    "\tvector v; \n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tvector_push_back(&v,&val1);\n",
    "\tassert(v.size == 1);\n",
    "\tassert(v.capacity == 1);\n",
    "\tint* p = vector_get(&v, 0);\n",
    "\tassert(*p == val1);\n",
    "\tvector_push_back(&v, &val2);\n",
    "\tp = vector_get(&v, 0);\n",
    "\tassert(*p == val1);\n",
    "\tassert(*(p + 1) == val2);\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "void vector_test_insert_read_struct(void)\n",
    "{\n",
    "\tstruct data {\n",
    "\t\tdouble d;\n",
    "\t\tint i;\n",
    "\t};\n",
    "\n",
    "\tprintf(\"vector_test_insert_read_struct: \");\n",
    "\tvector v; \n",
    "\tvector_init(&v, sizeof(struct data));\n",
    "\tstruct data d1 = { 0.05, 123 };\n",
    "\tstruct data d2 = { -1.9999e10, -9000 };\n",
    "\tvector_push_back(&v, &d1);\n",
    "\tvector_push_back(&v, &d2);\n",
    "\tstruct data* p = vector_get(&v, 0);\n",
    "\tassert((*p).d == d1.d); // Bitcopy should be exactly equal\n",
    "\tassert((*p).i == d1.i);\n",
    "\tp = vector_get(&v, 1);\n",
    "\tassert((*p).i == d2.i);\n",
    "\tassert((*p).d == d2.d);\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "void vector_test_safe_get(void)\n",
    "{\n",
    "\tprintf(\"vector_test_safe_get:  \");\n",
    "\tvector v; \n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tint val = 0xff;\n",
    "\tvector_push_back(&v, &val);\n",
    "\tvector_push_back(&v, &val);\n",
    "\n",
    "\tassert(NULL == vector_get_checked(&v, -1));\n",
    "\tassert(NULL == vector_get_checked(&v, 2));\n",
    "\tassert(val == *(int*)(vector_get_checked(&v, 1)));\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "void vector_test_reserve(void)\n",
    "{\n",
    "\tprintf(\"vector_test_reserve:  \");\n",
    "\tvector v; \n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tassert(v.capacity == 1);\n",
    "\tvector_reserve(&v, 10);\n",
    "\tassert(v.capacity == 10);\n",
    "\n",
    "\t// if we didn't assign the correct space VS will shout about overwriting memory in DEBUG\n",
    "\tint* p = (int*)v.data;\n",
    "\tfor (int i = 0; i < 10; ++i) {\n",
    "\t\t*p = i;\n",
    "\t\t++p;\n",
    "\t}\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "void foreach_increment_nodata(void* item)\n",
    "{\n",
    "\tassert(item != NULL);\n",
    "\tint* val = item;\n",
    "\t*val = *val + 1;\n",
    "}\n",
    "\n",
    "\n",
    "void vector_test_foreach_nodata(void)\n",
    "{\n",
    "\tvector v;\n",
    "\tprintf(\"vector_test_foreach_nodata: \");\n",
    "\n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tint val = 0;\n",
    "\n",
    "\tfor (size_t i = 0; i < 5; ++i)\n",
    "\t{\n",
    "\t\tvector_push_back(&v, &val);\n",
    "\t\t++val;\n",
    "\t}\n",
    "\n",
    "\tvector_foreach(&v, foreach_increment_nodata);\n",
    "\n",
    "\tfor (size_t i = 0; i < 5; ++i)\n",
    "\t{\n",
    "\t\tint* d = vector_get(&v, i);\n",
    "\t\tassert(*d == i + 1);\n",
    "\t}\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "\n",
    "int foreach_increment_data_null(void* item, void* data)\n",
    "{\n",
    "\tassert(item != NULL);\n",
    "\tassert(data == NULL);\n",
    "\tint* val = item;\n",
    "\t*val = *val + 1;\n",
    "\treturn 1;\n",
    "}\n",
    "\n",
    "\n",
    "void vector_test_foreach_data_1(void)\n",
    "{\n",
    "\tvector v;\t\n",
    "\tprintf(\"vector_test_foreach_data_1: \");\n",
    "\n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tint val = 0;\n",
    "\n",
    "\tfor (size_t i = 0; i < 5; ++i) {\n",
    "\t\tvector_push_back(&v, &val);\n",
    "\t\t++val;\n",
    "\t}\n",
    "\n",
    "\tvector_foreach_data(&v, foreach_increment_data_null, NULL);\n",
    "\n",
    "\tfor (size_t i = 0; i < 5; ++i) {\n",
    "\t\tint* d = vector_get(&v, i);\n",
    "\t\tassert(*d == i+1);\n",
    "\t}\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "struct foreach_data {\n",
    "\tint i;\n",
    "};\n",
    "\n",
    "int foreach_increment_data(void* item, void* data)\n",
    "{\n",
    "\tassert(item != NULL);\n",
    "\tassert(data != NULL);\n",
    "\tint *i = item;\n",
    "\t((struct foreach_data*)data)->i += *i;\n",
    "\treturn 1;\n",
    "}\n",
    "\n",
    "void vector_test_foreach_data_2(void)\n",
    "{\n",
    "\tvector v;\n",
    "\tprintf(\"vector_test_foreach_data_2: \");\n",
    "\n",
    "\tvector_init(&v, sizeof(int));\n",
    "\tint val = 4;\n",
    "\tint sum = 0;\n",
    "\tfor (size_t i = 0; i < 5; ++i) {\n",
    "\t\tvector_push_back(&v, &val);\n",
    "\t\tsum += val;\n",
    "\t\t++val;\n",
    "\t}\n",
    "\n",
    "\tstruct foreach_data data = {.i=0};\n",
    "\tvector_foreach_data(&v, foreach_increment_data, &data);\n",
    "\tassert(data.i == sum);\n",
    "\n",
    "\tprintf(\"OK\\\\n\");\n",
    "\tvector_free(&v);\n",
    "}\n",
    "\n",
    "void vector_test_all(void)\n",
    "{\n",
    "    vector_test_alloc_free();\n",
    "\tvector_test_insert_read_int();\n",
    "\tvector_test_insert_read_struct();\n",
    "\tvector_test_safe_get();\n",
    "\tvector_test_reserve();\n",
    "\tvector_test_foreach_nodata();\n",
    "\tvector_test_foreach_data_1();\n",
    "\tvector_test_foreach_data_2();\n",
    "}\n",
    "\n",
    "#endif // UNIT_TEST\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.197342Z",
     "start_time": "2021-08-20T07:56:43.190371Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/vector.c', 'w+') as f:\n",
    "    print(vector_c, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.239216Z",
     "start_time": "2021-08-20T07:56:43.233257Z"
    }
   },
   "outputs": [],
   "source": [
    "json_c = \"\"\"\\\n",
    "#include \"vector.h\"\n",
    "/* From\n",
    " * https://raw.githubusercontent.com/HarryDC/JsonParser/53197e0b84a7c8d3d57b840e40ea13efdd01d57d/src/json.c*/\n",
    "/*I have no idea why CLANG has a problem with enumed case labels\n",
    "TYPE_NULL = 0;\n",
    "TYPE_BOOL = 1;\n",
    "TYPE_NUMBER = 2;\n",
    "TYPE_OBJECT = 3;\n",
    "TYPE_ARRAY = 4;\n",
    "TYPE_STRING = 5;\n",
    "TYPE_KEY = 6;*/\n",
    "\n",
    "#include <assert.h>\n",
    "#include <ctype.h>\n",
    "#include <stddef.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "static int json_parse_value(const char **cursor, json_value *parent);\n",
    "\n",
    "int isspace_(char c) {\n",
    "  return isspace(c);\n",
    "}\n",
    "\n",
    "int iscntrl_(char c) {\n",
    "  return iscntrl(c);\n",
    "}\n",
    "\n",
    "static void skip_whitespace(const char **cursor) {\n",
    "  if (**cursor == '\\\\0')\n",
    "    return;\n",
    "  while (iscntrl_(**cursor) || isspace_(**cursor))\n",
    "    ++(*cursor);\n",
    "}\n",
    "\n",
    "static int has_char(const char **cursor, char character) {\n",
    "  skip_whitespace(cursor);\n",
    "  int success = **cursor == character;\n",
    "  if (success)\n",
    "    ++(*cursor);\n",
    "  return success;\n",
    "}\n",
    "\n",
    "static int json_parse_object(const char **cursor, json_value *parent) {\n",
    "  json_value result;\n",
    "  result.type = 3; /*TYPE_OBJECT*/;\n",
    "  /*vector_init(&result.value.object, sizeof(json_value));*/\n",
    "\n",
    "  int success = 1;\n",
    "  while (success && !has_char(cursor, '}')) {\n",
    "    json_value key;\n",
    "    key.type = 0; /*TYPE_NULL*/\n",
    "    json_value value;\n",
    "    value.type = 0; /*TYPE_NULL*/\n",
    "    success = json_parse_value(cursor, &key);\n",
    "    success = success && has_char(cursor, ':');\n",
    "    success = success && json_parse_value(cursor, &value);\n",
    "\n",
    "    if (success) {\n",
    "      /*vector_push_back(&result.value.object, &key);\n",
    "      vector_push_back(&result.value.object, &value);*/\n",
    "    } else {\n",
    "      json_free_value(&key);\n",
    "      break;\n",
    "    }\n",
    "    skip_whitespace(cursor);\n",
    "    if (has_char(cursor, '}'))\n",
    "      break;\n",
    "    else if (has_char(cursor, ','))\n",
    "      continue;\n",
    "    else\n",
    "      success = 0;\n",
    "  }\n",
    "\n",
    "  if (success) {\n",
    "    *parent = result;\n",
    "  } else {\n",
    "    json_free_value(&result);\n",
    "  }\n",
    "\n",
    "  return success;\n",
    "}\n",
    "\n",
    "static int json_parse_array(const char **cursor, json_value *parent) {\n",
    "  int success = 1;\n",
    "  if (**cursor == ']') {\n",
    "    ++(*cursor);\n",
    "    return success;\n",
    "  }\n",
    "  while (success) {\n",
    "    json_value new_value;\n",
    "    new_value.type = 0; /*TYPE_NULL*/\n",
    "    success = json_parse_value(cursor, &new_value);\n",
    "    if (!success)\n",
    "      break;\n",
    "    skip_whitespace(cursor);\n",
    "    /*vector_push_back(&parent->value.array, &new_value);*/\n",
    "    skip_whitespace(cursor);\n",
    "    if (has_char(cursor, ']'))\n",
    "      break;\n",
    "    else if (has_char(cursor, ','))\n",
    "      continue;\n",
    "    else\n",
    "      success = 0;\n",
    "  }\n",
    "  return success;\n",
    "}\n",
    "\n",
    "void json_free_value(json_value *val) {\n",
    "  if (!val)\n",
    "    return;\n",
    "\n",
    "  switch (val->type) {\n",
    "  case 5 /*TYPE_STRING*/: {\n",
    "    free(val->value.string);\n",
    "    val->value.string = 0;\n",
    "    break;\n",
    "  }\n",
    "  case 4 /*TYPE_ARRAY*/: {\n",
    "    /*vector_foreach(&(val->value.array), (void (*)(void *))json_free_value);\n",
    "    vector_free(&(val->value.array));*/\n",
    "    break;\n",
    "  }\n",
    "  case 3 /*TYPE_OBJECT*/: {\n",
    "    /*vector_foreach(&(val->value.array), (void (*)(void *))json_free_value);\n",
    "    vector_free(&(val->value.array));*/\n",
    "    break;\n",
    "  }\n",
    "  }\n",
    "\n",
    "  val->type = 0 /*TYPE_NULL*/;\n",
    "}\n",
    "\n",
    "int json_is_literal(const char **cursor, const char *literal) {\n",
    "  size_t cnt = strlen(literal);\n",
    "  if (strncmp(*cursor, literal, cnt) == 0) {\n",
    "    *cursor += cnt;\n",
    "    return 1;\n",
    "  }\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "static int json_parse_value(const char **cursor, json_value *parent) {\n",
    "  /* Eat whitespace */\n",
    "  int success = 0;\n",
    "  skip_whitespace(cursor);\n",
    "  switch (**cursor) {\n",
    "  case '\\\\0': {\n",
    "    /* If parse_value is called with the cursor at the end of the string that's a failure*/\n",
    "    success = 0;\n",
    "    break;\n",
    "  }\n",
    "  case '\"': {\n",
    "    ++*cursor;\n",
    "    const char *start = *cursor;\n",
    "    char *end = (char*) strchr(*cursor, '\"');\n",
    "    if (end) {\n",
    "      size_t len = end - start;\n",
    "      char *new_string = (char*) malloc((len + 1) * sizeof(char));\n",
    "      memcpy(new_string, start, len);\n",
    "      new_string[len] = '\\\\0';\n",
    "\n",
    "      if (len != strlen(new_string)) {\n",
    "        exit(100);\n",
    "      }\n",
    "\n",
    "      parent->type = 5 /*TYPE_STRING*/;\n",
    "      parent->value.string = new_string;\n",
    "\n",
    "      *cursor = end + 1;\n",
    "      success = 1;\n",
    "    }\n",
    "    break;\n",
    "  }\n",
    "  case '{': {\n",
    "    ++(*cursor);\n",
    "    skip_whitespace(cursor);\n",
    "    success = json_parse_object(cursor, parent);\n",
    "    break;\n",
    "  }\n",
    "  case '[': {\n",
    "    parent->type = 4 /*TYPE_ARRAY*/;\n",
    "    /*vector_init(&parent->value.array, sizeof(json_value));*/\n",
    "    ++(*cursor);\n",
    "    skip_whitespace(cursor);\n",
    "    success = json_parse_array(cursor, parent);\n",
    "    if (!success) {\n",
    "      /*vector_free(&parent->value.array);*/\n",
    "    }\n",
    "    break;\n",
    "  }\n",
    "  case 't': {\n",
    "    success = json_is_literal(cursor, \"true\");\n",
    "    if (success) {\n",
    "      parent->type = 1; /* TYPE_BOOL;*/\n",
    "      parent->value.boolean = 1;\n",
    "    }\n",
    "    break;\n",
    "  }\n",
    "  case 'f': {\n",
    "    success = json_is_literal(cursor, \"false\");\n",
    "    if (success) {\n",
    "      parent->type = 1; /* TYPE_BOOL;*/\n",
    "      parent->value.boolean = 0;\n",
    "    }\n",
    "    break;\n",
    "  }\n",
    "  case 'n': {\n",
    "    success = json_is_literal(cursor, \"null\");\n",
    "    break;\n",
    "  }\n",
    "  default: {\n",
    "    char *end;\n",
    "    double number = strtod(*cursor, &end);\n",
    "    if (*cursor != end) {\n",
    "      parent->type = 2 /*TYPE_NUMBER*/;\n",
    "      parent->value.number = number;\n",
    "      *cursor = end;\n",
    "      success = 1;\n",
    "    }\n",
    "  }\n",
    "  }\n",
    "\n",
    "  return success;\n",
    "}\n",
    "\n",
    "int json_parse(const char *input, json_value *result) {\n",
    "  const char** cursor = &input;\n",
    "  int val = json_parse_value(cursor, result);\n",
    "  if (strlen(*cursor) != 0){\n",
    "    return 0;\n",
    "  }\n",
    "  return val;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "  char my_string[10240];\n",
    "  json_value result;\n",
    "  result.type = 0;/*TYPE_NULL*/\n",
    "  int ret = -1;\n",
    "  \n",
    "  strcpy(my_string, argv[1]);\n",
    "  ret = json_parse(my_string, &result);\n",
    "  json_free_value(&result);\n",
    "  \n",
    "  return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:43.283625Z",
     "start_time": "2021-08-20T07:56:43.275877Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('subjects/json.c', 'w+') as f:\n",
    "    print(json_c, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject Registry\n",
    "\n",
    "We store all our subject programs under `program_src`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:45.946884Z",
     "start_time": "2021-08-20T07:56:45.937668Z"
    }
   },
   "outputs": [],
   "source": [
    "program_src = {\n",
    "    'calculator.c': 'calc_parse',\n",
    "    'cgidecode.c': 'cgi_decode',\n",
    "    'url_parse.c': 'url_parse',\n",
    "    'ini.c': 'ini_parse',\n",
    "    'csvparser.c': 'csv_parse'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Input Grammar from non-Stripped Binaries \n",
    "\n",
    "Non-stripped binaries are binaries that have debugging information built into it, which basically means if an executable is compiled with `gcc`'s `-g` flag, it contains debugging information. In order to derive an input from a non-stripped binary, we build a debugger which leverage the debugging information presence in the binary in order to produce an input grammar.\n",
    "\n",
    "In order to be able  recover an input grammar. We need to hook into the program runtime observe debugging information such as the arguments to a function, local variables and the context of execution by inspecting the currently observed `frame`.\n",
    "\n",
    "To do this, we make use of `GDB`, the GNU Project debugger which allow us to trace through a program and also gives us access to the same contextual information as we have seen previously in the example implemented in python.`GDB` provides a python API which can be use in debugging binary programs and also accessing program information at runtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugger\n",
    "\n",
    "Before we can start debugging programs, we use `GDB` python API to implement a debugger that would suit our aim by  creating an interface that provides functions which a standard debugger would have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:51.601777Z",
     "start_time": "2021-08-20T07:56:51.596950Z"
    }
   },
   "outputs": [],
   "source": [
    "class Debugger(object):\n",
    "    def run(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def step(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def break_at(self, line):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def start_program(self, inp, binary):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def event_loop(self):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GDBDebugger\n",
    "We provides a concrete implementation of the above interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:54.526882Z",
     "start_time": "2021-08-20T07:56:54.517052Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(Debugger):\n",
    "    def __init__(self, gdb, binary, inp, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.gdb, self.binary, self.inp = gdb, binary, inp\n",
    "        self.frames = []\n",
    "        self._set_printer()\n",
    "        self._set_logger()\n",
    "        self._skip_std_files()\n",
    "        self.tracer = GDBTracer(self.inp, files=self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:54.562228Z",
     "start_time": "2021-08-20T07:56:54.553272Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def run(self):\n",
    "        self.gdb.execute('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:54.598590Z",
     "start_time": "2021-08-20T07:56:54.594625Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def step(self):\n",
    "        self.gdb.execute('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:54.637246Z",
     "start_time": "2021-08-20T07:56:54.631478Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def break_at(self, line):\n",
    "        self.gdb.execute(\"break '%s'\" % line)\n",
    "        self.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:54.676986Z",
     "start_time": "2021-08-20T07:56:54.668212Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def start_program(self, inp, binary):\n",
    "        self.gdb.execute(\"set args '%s'\" % inp)\n",
    "        self.gdb.execute(\"file %s\" % binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_set_logger` function is used to configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:57.241058Z",
     "start_time": "2021-08-20T07:56:57.233682Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def _set_logger(self):\n",
    "        self.gdb.execute('set logging overwrite on')\n",
    "        self.gdb.execute('set logging redirect on')\n",
    "        self.gdb.execute('set logging on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When stepping through binary programs, we need to make sure we avoid stepping into files which are not of interest to us such as the *standard libraries files*. One of the ways to do this is to tell `GDB` to skip all files which are of a particular format, an example is the *.S files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:56:59.946845Z",
     "start_time": "2021-08-20T07:56:59.941008Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def _set_printer(self):\n",
    "        if not self.printer:\n",
    "            self.gdb.execute('set print address off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, in order to efficiently avoid stepping into files we are not interested, we define a variable `file` which holds an array of file names which we are interested in tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:02.670223Z",
     "start_time": "2021-08-20T07:57:02.663496Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def _skip_std_files(self):\n",
    "        self.gdb.execute('skip -gfi *.S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, in order to efficiently avoid stepping into files we are not interested, we define a variable `file` which holds an array of file names which we are interested in tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:05.257547Z",
     "start_time": "2021-08-20T07:57:05.247234Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files', [])\n",
    "        self.methods = kwargs.get('methods', [])\n",
    "        self.printer = kwargs.get('printer', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each step in our program we need to always check if we are within the context which we are most interested in. To do this, we provide the function `in_context` which take the selected frame at each *step* in our program an then to a check if we are still within the context that we are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:05.613963Z",
     "start_time": "2021-08-20T07:57:05.609681Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def in_context(self, frame):\n",
    "        file_name = frame.find_sal().symtab.fullname()\n",
    "        return any(file_name.endswith(f) for f in self.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T11:04:09.427957Z",
     "start_time": "2019-11-24T11:04:09.405328Z"
    }
   },
   "source": [
    "The function `get_event` keeps track of how frame are being created when stepping through our program. The idea behind this is that whenever a frame is newly created, it is added to the frame list and that shows that a function call has occurred within our program then we assign the event as a `call`. Also, whenever a frame is the last frame being added to our frame list that also implies that we are still within that particular frame  and then we assign the event as `line`. Lastly, if none of the above has occurred then it shows that particular frame has exited and then we assign our event as `return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:05.962585Z",
     "start_time": "2021-08-20T07:57:05.953257Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def get_event(self, frame):\n",
    "        fname = frame.name()\n",
    "        if fname not in self.frames:\n",
    "            self.frames.append(fname)\n",
    "            return 'call'\n",
    "        elif fname == self.frames[-1]:\n",
    "            return 'line'\n",
    "        else:\n",
    "            self.frames.pop()\n",
    "            return 'return'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `event_loop` starts our program and the auto-step through our program while it runs. Once we start our program we get the selected frame and then assign it to the variable called `frame`. The `frame` variable in gdb automatically becomes `False` when the program exits even though we never explicitly assign to it. Also, at each step in our program we check if there is a new frame and if the frame is within our scope of interest. If not, we instruct `GDB` to finish execution from the uninterested scope and then returns back to it's caller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:06.325450Z",
     "start_time": "2021-08-20T07:57:06.312335Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBDebugger(GDBDebugger):\n",
    "    def event_loop(self):\n",
    "        self.start_program(self.inp, self.binary)\n",
    "        self.break_at('main')\n",
    "        frame = self.gdb.selected_frame()\n",
    "        try:\n",
    "            while frame.is_valid():\n",
    "                if self.gdb.selected_frame() != frame:\n",
    "                    self.step()\n",
    "                    current_frame = self.gdb.selected_frame()\n",
    "                    if not self.in_context(current_frame):\n",
    "                        # simply finish the current function execution.\n",
    "                        self.gdb.execute('finish')\n",
    "                        continue\n",
    "                    event = self.get_event(current_frame)\n",
    "                    self.tracer.traceit(current_frame, event, None)\n",
    "                else:\n",
    "                    self.step()\n",
    "                    if not self.in_context(self.gdb.selected_frame()):\n",
    "                        self.gdb.execute('finish')\n",
    "        except gdb.error:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarExtractor\n",
    "\n",
    "Next, We also define a class called `VarExtractor` which provides various logic that can be used to extract and process variables which are contained a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:06.688767Z",
     "start_time": "2021-08-20T07:57:06.680752Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarExtractor:\n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract integer values\n",
    "The function `extract_int_val` takes a symbol which type is an integer as argument and then looks up such symbol in the frame and then returns the value of such symbols. This form of extraction works for an integer which does not have a pointer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:07.137863Z",
     "start_time": "2021-08-20T07:57:07.121923Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarExtractor(VarExtractor):\n",
    "    def extract_int_val(self, symbol):\n",
    "        return '{}'.format(symbol.value(self.frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dereference pointer types\n",
    "\n",
    "`dereference_pointer_type` is solely used for symbols which are of the type `pointer`. This function basically dereference a pointer type and then returns the actual type which it points to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:07.739712Z",
     "start_time": "2021-08-20T07:57:07.731938Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarExtractor(VarExtractor):\n",
    "    def dereference_pointer_type(self, symbol):\n",
    "        return symbol.value(self.frame).dereference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extract_struct_val` take a symbol which is of type `struct` and then returns the value as a key, value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:08.196735Z",
     "start_time": "2021-08-20T07:57:08.192805Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarExtractor(VarExtractor):\n",
    "    def extract_struct_val(self, struct):\n",
    "        return {\n",
    "            f.name: str(struct[f]).strip('\"')\n",
    "            for f in struct.type.fields()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pointer values\n",
    "\n",
    "The function `extract_pointer_val` which firstly dereference a pointer type and then returns the true type of the object it points to. Next, we check the type of the object being pointed to and then we extract the value and then return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:08.628972Z",
     "start_time": "2021-08-20T07:57:08.622109Z"
    }
   },
   "outputs": [],
   "source": [
    "class VarExtractor(VarExtractor):\n",
    "    def extract_pointer_val(self, symbol):\n",
    "        true_value = self.dereference_pointer_type(symbol)\n",
    "\n",
    "        if true_value.type.code == gdb.TYPE_CODE_INT:\n",
    "            return '{}'.format(true_value.address).strip('\"')\n",
    "\n",
    "        elif true_value.type.code == gdb.TYPE_CODE_STRUCT:\n",
    "            return self.extract_struct_val(true_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDBContext\n",
    "\n",
    "We've seen previously that the `Context` class provides easy access to the information such as the current module, and parameter names. We can also obtain same information using `GDB`  to access the frame as seen below.\n",
    "\n",
    "We call our new context class `GDBContext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:09.026409Z",
     "start_time": "2021-08-20T07:57:09.023109Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:09.042249Z",
     "start_time": "2021-08-20T07:57:09.034895Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBContext(Context):\n",
    "    def __init__(self, frame):\n",
    "        self.method = frame.name()\n",
    "        self.parameter_names = self.get_arg_names(frame)\n",
    "        self.line_no = frame.find_sal().line\n",
    "        self.file_name = frame.find_sal().symtab.fullname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_arg_names` is a custom function which takes a `frame` as input, extract the name of the arguments and return a list of argument names. `GDB` represents variables, constants, arguments as symbols in a block. In a more descriptive sense, a block is just a scope in the source code. Also, `gdb.Block` is iterable just as we can see in the `get_arg_names` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:09.459130Z",
     "start_time": "2021-08-20T07:57:09.451487Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBContext(GDBContext):\n",
    "    def get_arg_names(self, frame):\n",
    "        return [symbol.name for symbol in frame.block() if symbol.is_argument]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also extend the `extract_vars` which is a convenience method that acts on the frame within the `GDBContext` class. In this case we iterate through all `symbols` in the current `block`. If the symbol is a variable or an argument, we check what type they carry and then we extract their corresponding values based on their type and then we add them to  dictionary `vals` as defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:09.883676Z",
     "start_time": "2021-08-20T07:57:09.872380Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBContext(GDBContext):\n",
    "    def extract_vars(self, frame):\n",
    "        vals = {}\n",
    "        extractor = VarExtractor(frame)\n",
    "\n",
    "        symbols = [\n",
    "            sym for sym in frame.block() if sym.is_variable or sym.is_argument\n",
    "        ]\n",
    "        for symbol in symbols:\n",
    "            if symbol.type.code == gdb.TYPE_CODE_INT:\n",
    "                vals[symbol.name] = extractor.extract_int_val(symbol)\n",
    "\n",
    "            elif symbol.type.code == gdb.TYPE_CODE_PTR:\n",
    "                vals[symbol.name] = extractor.extract_pointer_val(symbol)\n",
    "\n",
    "        return {k1: v1 for k, v in vals.items() for k1, v1 in flatten(k, v)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  GDBTracer\n",
    "\n",
    "Previously, we have seen how `Tracer` class was used to trace through a python program to obtain the trace information. In our case, we define a new class `GDBTracer` that inherits the base implementation of our `Tracer` class, the only exception we have is to use the `GDBContext` class which we already defined above. To do this, we override the function `create_context` and then return an instance of `GDBContext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:10.376807Z",
     "start_time": "2021-08-20T07:57:10.373446Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import Tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: verify that your current version of fuzzingbook you use uses `create_context()` in the `traceit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:11.106781Z",
     "start_time": "2021-08-20T07:57:11.096066Z"
    }
   },
   "outputs": [],
   "source": [
    "class GDBTracer(Tracer):\n",
    "    def create_context(self, frame):\n",
    "        return GDBContext(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting all together\n",
    "\n",
    "Due to the limitation we have that `GDB` API is not a library, we cannot execute our implementation directly within the notebook cell. To address this limitation, we use the fuzzingbook `extract_class_definition` function to extract each of the classes we have implemented so far and then we write them to a `.py` file which would then be execute under `GDB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:12.278079Z",
     "start_time": "2021-08-20T07:57:12.275372Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:12.321121Z",
     "start_time": "2021-08-20T07:57:12.290114Z"
    }
   },
   "outputs": [],
   "source": [
    "tracer_head = \"\"\"\\\n",
    "import sys\n",
    "sys.path.extend([%s])\n",
    "sys.path.append('.')\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot._IP_REGISTERED = True # Hack\n",
    "import fuzzingbook_utils\n",
    "from GrammarMiner import GrammarMiner, Context, Tracer, Coverage, ScopedGrammarMiner, readable, flatten\n",
    "import jsonpickle\n",
    "import os\n",
    "import gdb\n",
    "\"\"\" % (', '.join(\"'%s'\" % str(i) for i in sys.path if i))\n",
    "debugger_src = fuzzingbook_utils.extract_class_definition(Debugger)\n",
    "context_src = fuzzingbook_utils.extract_class_definition(GDBContext)\n",
    "gdbtracer_src = fuzzingbook_utils.extract_class_definition(GDBTracer)\n",
    "varextractor_src = fuzzingbook_utils.extract_class_definition(VarExtractor)\n",
    "gdbdebugger_src = fuzzingbook_utils.extract_class_definition(GDBDebugger)\n",
    "tracer_tail=\"\"\"\n",
    "file_name = 'gdbtrace'\n",
    "def recover_trace(f, inp, **kwargs):\n",
    "    d = GDBDebugger(gdb, f, inp, **kwargs)\n",
    "    d.event_loop()\n",
    "    with open(file_name, 'w+') as f:\n",
    "        print(jsonpickle.encode(d.tracer.trace), file=f)\n",
    "binary = 'a.out'\n",
    "recover_trace(binary, arg0, files=files.split(' '))\n",
    "\"\"\"\n",
    "tracer_src = '\\n'.join([tracer_head, debugger_src, context_src, gdbtracer_src, varextractor_src, gdbdebugger_src, tracer_tail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:12.327023Z",
     "start_time": "2021-08-20T07:57:12.324121Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('build/debugger.py', 'w+') as f:\n",
    "    #print(tracer_src, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The method recover grammar\n",
    "`recover_grammar` function is similar to the one seen previously. The exception it has is that we execute the `debugger.py` file under `GDB` and then we read the trace before updating the scope grammar miner instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:12.753693Z",
     "start_time": "2021-08-20T07:57:12.746872Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import ScopedGrammarMiner, readable\n",
    "import jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:12.774469Z",
     "start_time": "2021-08-20T07:57:12.760968Z"
    }
   },
   "outputs": [],
   "source": [
    "def recover_grammar(inps, src):\n",
    "    traces = []\n",
    "    miner = ScopedGrammarMiner()\n",
    "\n",
    "    for inp in inps:\n",
    "        arg = '\\'py arg0=\"%s\"\\'' % inp\n",
    "        argfiles = '\\'py files=\"%s\"\\'' % src\n",
    "        print(arg)\n",
    "        !gdb --batch-silent -ex {arg} -ex {argfiles} -x debugger.py\n",
    "        with open('gdbtrace', 'rb') as f:\n",
    "            traces.append((inp, jsonpickle.decode(f.read())))\n",
    "    \n",
    "    for inp, trace in traces:\n",
    "        miner.update_grammar(inp, trace)\n",
    "    return (readable(miner.clean_grammar()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Input Grammar from Stripped Binaries\n",
    "\n",
    "Stripped Binaries are binaries that does not include debugging symbols during program execution. This can be produced by including `-s` flag when compiling the program with `gcc`.\n",
    "When considering stripped binaries, we would understand that our above implementation cannot directly be used to obtain an input grammar from such binaries since they do not contain debugging information. \n",
    "\n",
    "One thing to consider is that stripped binaries only contains sets of `assembly instructions` which are usually executed sequentially at runtime. With this idea, we can observe these sets of instrutions and then infer some useful program informations which would be useful to produce meaningful input grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly Instructions\n",
    "\n",
    "An assembly instruction is typically made up of a line address, an instruction type which specifies what type of action of operation to be taken and also a source and a destination registers\n",
    "\n",
    "Below is an example of an instruction that moves a value from one register to another;\n",
    "\n",
    "`0x555555554892:      mov    %rsp,%rbp` where `0x555555554892` is the current line address, `mov` is the type of instruction that should be carried out and lastly `%rsp`,`%rbp` which represents the source and destination registers respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assembly Instruction as an Object\n",
    "\n",
    "With the information we can obtain from each assembly instruction, we represents this as an object called `Instruction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:14.079059Z",
     "start_time": "2021-08-20T07:57:14.075643Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "global_declarations = '''\n",
    "CALL = 'callq'\n",
    "RETURN = 'retq'\n",
    "LINE = 'line'\n",
    "ARG_REGISTERS = ['rdi', 'rsi', 'rdx', 'rcx', 'r8', 'r9']\n",
    "REGISTERS = ARG_REGISTERS + ['rax', 'eax', 'edi' 'esi', 'edx', 'ecx']\n",
    "UNWANTED = [\n",
    "    'leaveq', 'retq', 'nop', 'je', 'jne', 'jmp', 'jle', 'jmpq', 'jae', 'jbe',\n",
    "    'cltq', 'ja', 'jb', 'js'\n",
    "]\n",
    "ADDR_COUNTER_ = 0\n",
    "F_ADDR_COUNTER_ = 0\n",
    "L_ADDR_COUNTER = 0\n",
    "CALL_STORE = []\n",
    "LEN_OF_ADDR = 14\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:14.100093Z",
     "start_time": "2021-08-20T07:57:14.093017Z"
    }
   },
   "outputs": [],
   "source": [
    "class Instruction:\n",
    "    def __init__(self, instr):\n",
    "        self.symbol_name = None\n",
    "        self.pointed_address = None\n",
    "        self.dest_reg = None\n",
    "        self.instr_type = None\n",
    "        self._parse(instr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_parse()` takes an instruction as string and then extract information such as the current line address, function address, registers as well as instruction type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:14.559754Z",
     "start_time": "2021-08-20T07:57:14.541828Z"
    }
   },
   "outputs": [],
   "source": [
    "class Instruction(Instruction):\n",
    "    def _parse(self, instr):\n",
    "        instr_list = instr.split()\n",
    "        instr_list.pop(0)\n",
    "\n",
    "        self.current_address = instr_list[0]\n",
    "        if \"<\" in instr_list[1]:\n",
    "            instr_list.pop(1)\n",
    "        self.instr_type = instr_list[1]\n",
    "\n",
    "        if self.instr_type == CALL:\n",
    "            self.pointed_address = self.get_pointed_value(instr_list[2])\n",
    "            if len(instr_list) > 3:\n",
    "                self.symbol_name = instr_list[-1]\n",
    "\n",
    "        elif self.instr_type in UNWANTED:\n",
    "            return\n",
    "        else:\n",
    "            if len(instr_list) > 2:\n",
    "                d = instr_list[2]\n",
    "            else:\n",
    "                return\n",
    "\n",
    "            if d[-1] != ')':\n",
    "                if d[-3:] in REGISTERS:\n",
    "                    self.dest_reg = d[-3:]\n",
    "                else:\n",
    "                    r = instr_list[-1][-3:]\n",
    "                    self.dest_reg = r if r in REGISTERS else None\n",
    "            elif re.match(r',\\d\\)', d[-3:]):\n",
    "                d = d.split(',')\n",
    "                if d[0][1:] in REGISTERS:\n",
    "                    self.dest_reg = d[0][1:]\n",
    "            else:\n",
    "                for r in REGISTERS:\n",
    "                    if r in d:\n",
    "                        self.dest_reg = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:14.577584Z",
     "start_time": "2021-08-20T07:57:14.570908Z"
    }
   },
   "outputs": [],
   "source": [
    "class Instruction(Instruction):\n",
    "    def get_pointed_value(self, val):\n",
    "        val = val.strip('%*')\n",
    "        if val in REGISTERS:\n",
    "            ptr_addr = gdb.execute('x/s $%s' % (val),\n",
    "                                   to_string=True).split(':')\n",
    "            return ptr_addr[0]\n",
    "        return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinaryVarExtractor\n",
    "\n",
    "The class `BinaryVarExtractor` is a variant of the `VarExtractor` defined above which extracts variable values from X86 register as well as memory address that points to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.037122Z",
     "start_time": "2021-08-20T07:57:15.026947Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor:\n",
    "    def __init__(self, inp):\n",
    "        self.inp = inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.056184Z",
     "start_time": "2021-08-20T07:57:15.046235Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor(BinaryVarExtractor):\n",
    "    def read_reg_as_string(self, register):\n",
    "        str_result = gdb.execute('x/s $%s' % register, to_string=True)\n",
    "        for index, char in enumerate(str_result):\n",
    "            if str_result[index] == ':':\n",
    "                addr = str_result[:index]\n",
    "                break\n",
    "        return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.068970Z",
     "start_time": "2021-08-20T07:57:15.058874Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor(BinaryVarExtractor):\n",
    "    def get_address(self, addr):\n",
    "        s = gdb.execute('x/a %s' % addr, to_string=True)\n",
    "        for index, char in enumerate(s):\n",
    "            if s[index] == ':':\n",
    "                addr = s[index + 1:]\n",
    "                break\n",
    "        return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.090976Z",
     "start_time": "2021-08-20T07:57:15.078241Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor(BinaryVarExtractor):\n",
    "    def read_address(self, addr):\n",
    "        if len(addr) == ADDR_LENGTH:\n",
    "            str_result = gdb.execute('x/s %s' % addr, to_string=True)\n",
    "            key, value = self.split_string_value(str_result)\n",
    "\n",
    "            if value not in self.inp:\n",
    "                addr_result = self.get_address(key)\n",
    "                s1 = gdb.execute('x/s %s' % addr_result, to_string=True)\n",
    "                k1, v1 = self.split_string_value(s1)\n",
    "                return v1\n",
    "            return value\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.104693Z",
     "start_time": "2021-08-20T07:57:15.093329Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor(BinaryVarExtractor):\n",
    "    def split_string_value(self, strval):\n",
    "        for count, char in enumerate(strval):\n",
    "            if strval[count] == ':':\n",
    "                key = strval[:count]\n",
    "                value = strval[count + 3:-2]\n",
    "                break\n",
    "        return key, value.replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.114165Z",
     "start_time": "2021-08-20T07:57:15.108433Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryVarExtractor(BinaryVarExtractor):\n",
    "    def read_register(self, register):\n",
    "        addr = self.read_reg_as_string(register)\n",
    "        return self.read_address(addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame\n",
    "\n",
    "In stripped binaries, we do not have access to stack frame unlike non-stripped binaries.\n",
    "As a solution, we build a frame class that represents information we would normally have in a stack frame.\n",
    "\n",
    "The idea of this frame is that whenever we observe a `callq` instruction which represents a `call` event, we instantiate a new frame. All other instruction types are treated as `line` event with the exception of `retq` instruction which represents `return` event.\n",
    "\n",
    "Furthermore, when there is an `line` event we do not need to create a new frame, instead we update the current frame object such as the local variable, current line address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.608001Z",
     "start_time": "2021-08-20T07:57:15.599667Z"
    }
   },
   "outputs": [],
   "source": [
    "helper_methods = \"\"\"\n",
    "ADDR_STORE = {}\n",
    "F_ADDR_STORE = {}\n",
    "L_ADDR_STORE = {}\n",
    "FN_DICT = {}\n",
    "ADDR_LENGTH = 14\n",
    "\n",
    "def get_addr(addr, t):\n",
    "    global ADDR_COUNTER_\n",
    "    if t == 'arg':\n",
    "        ADDR_COUNTER_ += 1\n",
    "        return ADDR_COUNTER_\n",
    "    if addr in ADDR_STORE: return ADDR_STORE[addr]\n",
    "    ADDR_COUNTER_ += 1\n",
    "    ADDR_STORE[addr] = ADDR_COUNTER_\n",
    "    return ADDR_STORE[addr]\n",
    "    \n",
    "def get_fn_addr(addr):\n",
    "    global F_ADDR_COUNTER_\n",
    "    if addr in F_ADDR_STORE: return F_ADDR_STORE[addr]\n",
    "    F_ADDR_COUNTER_ += 1\n",
    "    F_ADDR_STORE[addr] = F_ADDR_COUNTER_\n",
    "    return F_ADDR_STORE[addr]\n",
    "    \n",
    "def get_fn(fnaddr):\n",
    "    fn_dict = {}\n",
    "    with open(f'function_names', 'rb') as f:\n",
    "        fn_dict = jsonpickle.decode(f.read())\n",
    "    return fn_dict[fnaddr] if fnaddr in fn_dict.keys() else fnaddr\n",
    "    \n",
    "def get_var(varaddr, t):\n",
    "    aid = get_addr(varaddr, t)\n",
    "    return \"var_%d\" % aid\n",
    "    \n",
    "def get_lno(addr):\n",
    "    global L_ADDR_COUNTER\n",
    "    if addr in L_ADDR_STORE: return 'a_%d' % (L_ADDR_STORE[addr])\n",
    "    L_ADDR_COUNTER += 1\n",
    "    L_ADDR_STORE[addr] = L_ADDR_COUNTER\n",
    "    s = 'a_%d' % (L_ADDR_STORE[addr])\n",
    "    return s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:15.627886Z",
     "start_time": "2021-08-20T07:57:15.622886Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    def __init__(self, instr, inp):\n",
    "        self.inp = inp\n",
    "        self.arguments = []\n",
    "        self.locals_vars = {}\n",
    "        self.line_no = None\n",
    "        self.file_name = None\n",
    "        self.function = None\n",
    "        self.bextr = BinaryVarExtractor(inp)\n",
    "        self._parse(instr)\n",
    "        CALL_STORE.append(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_read_register()` looks up the content of the register and then return a variable name along with the content of the register as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:16.121602Z",
     "start_time": "2021-08-20T07:57:16.113848Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame(Frame):\n",
    "    def _read_register(self, register, l_no, tag):\n",
    "        str_val = self.bextr.read_register(register)\n",
    "        var = get_var(l_no, tag)\n",
    "        return (var, str_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_read_arg_register()` is used to get the content of the first 6 registers which by convention is used to store arguments of a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:16.613775Z",
     "start_time": "2021-08-20T07:57:16.606291Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame(Frame):\n",
    "    def _read_arg_register(self):\n",
    "        unique_args = []\n",
    "        vals = [\n",
    "            self._read_register(reg, self.line_no, 'arg')\n",
    "            for reg in ARG_REGISTERS\n",
    "        ]\n",
    "\n",
    "        for k, v in vals:\n",
    "            if not unique_args:\n",
    "                unique_args.append((k, v))\n",
    "            else:\n",
    "                lst = [v for k, v in unique_args]\n",
    "                if v in lst: continue\n",
    "                else: unique_args.append((k, v))\n",
    "        args = {k: v for k, v in unique_args if v in self.inp}\n",
    "        return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_parse()` is used to set the information contained in an instruction which is been passed to the frame on instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:17.203960Z",
     "start_time": "2021-08-20T07:57:17.192228Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame(Frame):\n",
    "    def _parse(self, instr):\n",
    "        self.function = get_fn(instr.pointed_address)\n",
    "        self.line_no = get_lno(instr.current_address.strip(':'))\n",
    "        self.arguments = self._read_arg_register()\n",
    "        self.file_name = 'a.out'\n",
    "        self.locals_vars.update(self.arguments)\n",
    "        self.event = 'call'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_get_event()` sets each event based on the type of instruction being executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:17.860380Z",
     "start_time": "2021-08-20T07:57:17.856256Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame(Frame):\n",
    "    def _get_event(self, instr_type):\n",
    "        if instr_type == CALL:\n",
    "            return 'call'\n",
    "        elif instr_type == RETURN:\n",
    "            return 'return'\n",
    "        else:\n",
    "            return 'line'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `update()`update the current frame's local variables, and line address as instructions are being stepped through. Also, it keeps track of all `call` sequence as well as remove the correponding frame whenever there is a `return` event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:18.389691Z",
     "start_time": "2021-08-20T07:57:18.379833Z"
    }
   },
   "outputs": [],
   "source": [
    "class Frame(Frame):\n",
    "    def update(self, instr):\n",
    "        if CALL_STORE and self.function != CALL_STORE[-1].function:\n",
    "            self.function = CALL_STORE[-1].function\n",
    "            self.arguments = CALL_STORE[-1].arguments\n",
    "            self.locals_vars = CALL_STORE[-1].locals_vars\n",
    "\n",
    "        self.line_no = get_lno(instr.current_address.strip(':'))\n",
    "        self.event = self._get_event(instr.instr_type)\n",
    "        if self.event == 'return' and CALL_STORE:\n",
    "            CALL_STORE.pop()\n",
    "\n",
    "        if instr.dest_reg is not None:\n",
    "            var, val = self._read_register(instr.dest_reg,\n",
    "                                           instr.current_address, 'var')\n",
    "            self.locals_vars[var] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Context\n",
    "\n",
    "Using the frame object we created, we use this to update our context class just like we did above in the case of the non-stripped binaries implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:19.414606Z",
     "start_time": "2021-08-20T07:57:19.408296Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryContext(GDBContext):\n",
    "    def __init__(self, frame):\n",
    "        self.method = frame.function\n",
    "        self.parameter_names = [k for k, v in frame.arguments.items()]\n",
    "        self.line_no = frame.line_no\n",
    "        self.file_name = frame.file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:19.430903Z",
     "start_time": "2021-08-20T07:57:19.424261Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryContext(BinaryContext):\n",
    "    def extract_vars(self, frame):\n",
    "        return {k1: v1 for k, v in frame.locals_vars.items() for k1, v1 in flatten(k, v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:19.454459Z",
     "start_time": "2021-08-20T07:57:19.447858Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryContext(BinaryContext):\n",
    "    def __repr__(self):\n",
    "        return \"%s:%s:%s(%s)\" % self._t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Tracer\n",
    "\n",
    "We update our tracer which basically use our new context class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:19.969689Z",
     "start_time": "2021-08-20T07:57:19.963354Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryTracer(GDBTracer):\n",
    "    def create_context(self, frame):\n",
    "        return BinaryContext(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Debugger\n",
    "\n",
    "The binary debugger makes use of `gdb` commands which can be used to step through x86 assembly instructons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:21.139700Z",
     "start_time": "2021-08-20T07:57:21.134725Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(GDBDebugger):\n",
    "    def __init__(self, gdb, binary, inp, **kwargs):\n",
    "        super().__init__(gdb, binary, inp, **kwargs)\n",
    "        self.tracer = BinaryTracer(self.inp, files=self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:21.157643Z",
     "start_time": "2021-08-20T07:57:21.150995Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def break_at(self, address):\n",
    "        self.gdb.execute(\"break *%s\" % address)\n",
    "\n",
    "    def finish(self):\n",
    "        self.gdb.execute('finish')\n",
    "\n",
    "    def step(self):\n",
    "        self.gdb.execute('stepi')\n",
    "\n",
    "    def resume(self):\n",
    "        self.gdb.execute('continue')\n",
    "\n",
    "    def nexti(self):\n",
    "        self.gdb.execute('nexti')\n",
    "\n",
    "    def get_instruction(self):\n",
    "        return self.gdb.execute('x/i $rip', to_string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_event()` is used to assign events based which can be either a `call` which represents a new frame instantiation, `line` event which represents a frame update as well as `return` which represent when a frame does not more exist in the current context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:21.716011Z",
     "start_time": "2021-08-20T07:57:21.706728Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def get_event(self, frame):\n",
    "        fname = frame.function\n",
    "        if fname not in self.frames:\n",
    "            self.frames.append(fname)\n",
    "            return 'call'\n",
    "        elif fname == self.frames[-1]:\n",
    "            return 'line'\n",
    "        else:\n",
    "            self.frames.pop()\n",
    "            return 'return'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to debug stripped binaries, the first thing to consider is looking for the entry point address to the program. The function `get_entry_point()` is used to extract the entry point address to the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:22.281490Z",
     "start_time": "2021-08-20T07:57:22.271876Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def get_entry_point(self):\n",
    "        self.start_program(self.inp, self.binary)\n",
    "        self.run()\n",
    "        info_file = self.gdb.execute('info file', to_string=True)\n",
    "        entry_address = ''\n",
    "        for line in info_file.splitlines():\n",
    "            if 'Entry point' in line:\n",
    "                entry_address = line.split(':')[1]\n",
    "                break\n",
    "        return entry_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the entry point address has been gotten, we then need to locate the address to the function `main()` which istypically where the program starts its execution from. To get this, we used the function `get_main()` to derive the main address that points to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:22.991063Z",
     "start_time": "2021-08-20T07:57:22.980410Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def get_main(self):\n",
    "        self.gdb.execute('set confirm off')\n",
    "        entry_addr = self.get_entry_point()\n",
    "        self.break_at(entry_addr)\n",
    "        self.run()\n",
    "\n",
    "        instructions = []\n",
    "        while True:\n",
    "            next_i = self.get_instruction()\n",
    "            if CALL in next_i:\n",
    "                break\n",
    "            instructions.append(next_i)\n",
    "            self.step()\n",
    "\n",
    "        instr = instructions[-1].split()\n",
    "        if len(instr) == 6: s = instr[3]\n",
    "        else: s = instr[4]\n",
    "\n",
    "        reg = s[-3:]\n",
    "        main_addr = gdb.execute('p/x $%s' % reg, to_string=True)\n",
    "        main_addr = main_addr.partition(\"= \")\n",
    "\n",
    "        return main_addr[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order not to go out of context (i.e stepping into represents standard libraries instructions), function `get_address_range()` is used to get the address range of the set of instruction which our programs contains. This would serve as a guiding path when stepping through instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:23.589760Z",
     "start_time": "2021-08-20T07:57:23.582630Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def get_address_range(self):\n",
    "        start_addr = None\n",
    "        end_addr = None\n",
    "        mappings = self.gdb.execute('info proc mappings', to_string=True)\n",
    "\n",
    "        for i, line in enumerate(mappings.splitlines()):\n",
    "            if i == 4:\n",
    "                start_addr = line.split()[0]\n",
    "            elif i == 6:\n",
    "                end_addr = line.split()[1]\n",
    "        return (start_addr, end_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `in_scope()` uses the address range to make the debugger aware of when it is on the right path or when it encounters a wrong path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:24.157920Z",
     "start_time": "2021-08-20T07:57:24.153421Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def in_scope(self, instr, start, end):\n",
    "        instr = instr.split()\n",
    "        instr.pop(0)\n",
    "\n",
    "        current_addr = instr[0].strip(':')\n",
    "        hex_val = int(current_addr, 16)\n",
    "        if hex_val in range(int(start, 16), int(end, 16)):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `event_loop()` encompasses and makes use of all the logic defined above for the debugger,in order to step through all the instruction set in the right path to produce a trace which would be use to derive our desired grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:24.742711Z",
     "start_time": "2021-08-20T07:57:24.733414Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugger(BinaryDebugger):\n",
    "    def event_loop(self):\n",
    "        main = self.get_main()\n",
    "        self.break_at(main)\n",
    "        self.resume()\n",
    "\n",
    "        start, end = self.get_address_range()\n",
    "        nexti = ''\n",
    "        current_frame = None\n",
    "        while True:\n",
    "            try:\n",
    "                nexti = self.get_instruction()\n",
    "                if self.in_scope(nexti, start, end):\n",
    "                    h = Instruction(nexti)\n",
    "                    if h.instr_type == CALL:\n",
    "                        if h.symbol_name not in self.methods and\\\n",
    "                            h.symbol_name != None:\n",
    "                            self.nexti()\n",
    "                            continue\n",
    "                        else:\n",
    "                            self.step()\n",
    "                            current_frame = Frame(h, self.inp)\n",
    "                    else:\n",
    "                        self.step()\n",
    "                        if current_frame != None:\n",
    "                            current_frame.update(h)\n",
    "                        else:\n",
    "                            continue\n",
    "                    event = self.get_event(current_frame)\n",
    "                    self.tracer.traceit(current_frame, event, None)\n",
    "                else:\n",
    "                    self.finish()\n",
    "            except gdb.error:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `InputStack` class in order to account for fragments with single length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:25.886497Z",
     "start_time": "2021-08-20T07:57:25.881270Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import InputStack, ScopedVars, ScopeTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:25.901392Z",
     "start_time": "2021-08-20T07:57:25.895182Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryInputStack(InputStack):\n",
    "    def __init__(self, i, fragment_len):\n",
    "        super().__init__(i, fragment_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:25.918745Z",
     "start_time": "2021-08-20T07:57:25.908979Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScopedVars(ScopedVars):\n",
    "    def create_call_stack(self, i):\n",
    "        return BinaryInputStack(i, fragment_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:25.928912Z",
     "start_time": "2021-08-20T07:57:25.922370Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def create_assignments(self, *args):\n",
    "        return ScopedVars(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Scope TreeMiner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:26.537426Z",
     "start_time": "2021-08-20T07:57:26.533414Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import ScopeTreeMiner, to_nonterminal, is_nonterminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `BinaryScopeTreeMiner` is same as the `ScopeTreeMiner`, the only difference is that since line numbers are represented as string address, we change the format from `%d` to `%s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:27.349585Z",
     "start_time": "2021-08-20T07:57:27.339728Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryScopeTreeMiner(ScopeTreeMiner):\n",
    "    def nt_var(self, key):\n",
    "        method, seq, var, lno = key\n",
    "        return to_nonterminal(\"%s@%s:%s\" % (method, lno, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:27.362602Z",
     "start_time": "2021-08-20T07:57:27.356197Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryScopeTreeMiner(BinaryScopeTreeMiner):\n",
    "    def string_part_of_value(self, part, value):\n",
    "        return (part in value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Scope Grammar Miner\n",
    "\n",
    "The class `BinaryScopedGrammarMiner` is the same as the class `ScopedGrammarMiner` with the only difference being that we now use our newly updated`BinaryScopeTreeMiner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:28.006227Z",
     "start_time": "2021-08-20T07:57:28.002896Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import ScopedGrammarMiner, START_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:28.037132Z",
     "start_time": "2021-08-20T07:57:28.022038Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryScopedGrammarMiner(ScopedGrammarMiner):\n",
    "    def create_tree_miner(self, *args):\n",
    "        return BinaryScopeTreeMiner(*args)\n",
    "\n",
    "    def create_tracker(self, *args):\n",
    "        return ScopeTracker(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that, sometimes one finds that our central assumption -- that a fragment consumed by a function can be replaced by another fragment consumed by the same function elsewhere -- doesn't hold. This can be seen in functions that take an additional argument to specify what it should match. In such cases, we want to try and find out how to distinguish between these function invocations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching and book keeping variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.219374Z",
     "start_time": "2021-08-20T07:57:30.215424Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "NODE_REGISTER = {}\n",
    "EXEC_MAP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.234603Z",
     "start_time": "2021-08-20T07:57:30.228541Z"
    }
   },
   "outputs": [],
   "source": [
    "def reset_generalizer():\n",
    "    global EXEC_MAP\n",
    "    global NODE_REGISTER\n",
    "    EXEC_MAP.clear()\n",
    "    NODE_REGISTER.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.253421Z",
     "start_time": "2021-08-20T07:57:30.249268Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_mined_tree(tree, executable, inp):\n",
    "    return {'tree': tree, 'original': executable, 'arg': inp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.272427Z",
     "start_time": "2021-08-20T07:57:30.268342Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_nt(v):\n",
    "    return len(v) > 1 and (v[0], v[-1]) == ('<', '>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small library function to convert from tuple to lists so that we can modify a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.938399Z",
     "start_time": "2021-08-20T07:57:30.933122Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_modifiable(derivation_tree):\n",
    "    node, children, *rest = derivation_tree\n",
    "    return [node, [to_modifiable(c) for c in children], *rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:30.964589Z",
     "start_time": "2021-08-20T07:57:30.954568Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_to_str(tree):  # Non recursive\n",
    "    expanded = []\n",
    "    to_expand = [tree]\n",
    "    while to_expand:\n",
    "        (key, children, *rest), *to_expand = to_expand\n",
    "        if is_nt(key):\n",
    "            to_expand = children + to_expand\n",
    "        else:\n",
    "            assert not children\n",
    "            expanded.append(key)\n",
    "    return ''.join(expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_ref()` takes a `node` datastructure and searches for `node_name`. It returns the first instance found. This allows us to easily swap nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:31.670052Z",
     "start_time": "2021-08-20T07:57:31.665884Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ref(node, node_name):\n",
    "    name, children, *rest = node\n",
    "    if name == node_name:\n",
    "        return node\n",
    "    for child in children:\n",
    "        res = get_ref(child, node_name)\n",
    "        if res is not None: return res\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `replace_nodes()` function try to replace the contents of the first node with the _contents_ of the second (That is, the tree that has these nodes will automatically be modified), collect the produced string from the tree, and reset any changes. The arguments are tuples with the following format: (node, file_name, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:32.324633Z",
     "start_time": "2021-08-20T07:57:32.320155Z"
    }
   },
   "outputs": [],
   "source": [
    "def deep_copy(t):  # Python deepcopy is a bit buggy\n",
    "    v = json.dumps(t)\n",
    "    return json.loads(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:32.349751Z",
     "start_time": "2021-08-20T07:57:32.337983Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace the given node in a2 by the node in a1\n",
    "def replace_nodes(a2, a1):\n",
    "    node2, _, t2 = a2\n",
    "    node1, _, t1 = a1\n",
    "    str2_old = tree_to_str(t2)\n",
    "\n",
    "    # first change the name of the node, then copy the tree.\n",
    "    tmpl_name = '___bminer___'\n",
    "    old_name = node2[0]\n",
    "    node2[0] = tmpl_name\n",
    "    t2_new = deep_copy(t2)\n",
    "    node2[0] = old_name\n",
    "\n",
    "    # now find the reference to tmpl_name in t2_new\n",
    "    node2 = get_ref(t2_new, tmpl_name)\n",
    "    node2.clear()\n",
    "    for n in node1:\n",
    "        node2.append(n)\n",
    "    str2_new = tree_to_str(t2_new)\n",
    "    assert str2_old != str2_new\n",
    "    return t2_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a given node be replaced with another? The idea is, given two nodes (possibly from two trees), can the first node be replaced by the second, and still result in a valid string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:33.120772Z",
     "start_time": "2021-08-20T07:57:33.114377Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_a_replaceable_with_b(a1, a2, module):\n",
    "    n1, f1, t1 = a1\n",
    "    n2, f2, t2 = a2\n",
    "    if tree_to_str(n1) == tree_to_str(n2): return True\n",
    "    t_x = replace_nodes(a1, (('XXXX', []), None, t2))\n",
    "    x = tree_to_str(t_x)\n",
    "    updated_tree = replace_nodes(a1, a2)\n",
    "    o = tree_to_str(t1)\n",
    "    v = check(o, x, n1[0], updated_tree, module, tree_to_str(a1[0]), tree_to_str(a2[0]))\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:33.139537Z",
     "start_time": "2021-08-20T07:57:33.134710Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_compatible(a1, a2, module):\n",
    "    t1 = is_a_replaceable_with_b(a1, a2, module)\n",
    "    if not t1: return False\n",
    "    t2 = is_a_replaceable_with_b(a2, a1, module)\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are fundamentally, two kinds of nodes. The first kind of node is a method node, that correspond to a method call. The second is a node that corresponds to a pseudo-method -- that is, a node that represents a loop or a conditional. Below are the predicates that identify such methods, parses, and reconstructs such nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.013667Z",
     "start_time": "2021-08-20T07:57:34.004509Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_node_method(node):\n",
    "    node_name = node[0]\n",
    "    if (node_name[0], node_name[-1]) != ('<', '>'): return False\n",
    "    return not is_node_pseudo(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.032102Z",
     "start_time": "2021-08-20T07:57:34.023419Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_node_pseudo(node):\n",
    "    node_name = node[0]\n",
    "    if (node_name[0], node_name[-1]) != ('<', '>'): return False\n",
    "    if ':if_' in node_name: return True\n",
    "    if ':while_' in node_name: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.042595Z",
     "start_time": "2021-08-20T07:57:34.036349Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pseudo_name(node_name):\n",
    "    assert (node_name[0], node_name[-1]) == ('<', '>')\n",
    "    return decode_name(node_name[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.064667Z",
     "start_time": "2021-08-20T07:57:34.052898Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_method_name(mname):\n",
    "    assert (mname[0], mname[-1]) == ('<', '>')\n",
    "    name = mname[1:-1]\n",
    "    if '.' in name:\n",
    "        nname, my_id = name.split('.')\n",
    "        return nname, my_id\n",
    "    else:\n",
    "        return name, '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.083908Z",
     "start_time": "2021-08-20T07:57:34.071187Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_name(node_name_stack):\n",
    "    node_name, mstack = node_name_stack.split('#')\n",
    "    method_stack = json.loads(mstack)\n",
    "    method_ctrl_alt_name, can_empty = node_name.split(' ')\n",
    "    method, ctrl_cid_altid = method_ctrl_alt_name.split(':')\n",
    "    ctrl, cid_altid = ctrl_cid_altid.split('_')\n",
    "    assert ctrl in {'while', 'if'}\n",
    "    cid, altid = cid_altid.split(',')\n",
    "\n",
    "    if 'while' == ctrl:\n",
    "        assert altid == '0'\n",
    "    return method, ctrl, int(cid), altid, can_empty, method_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.098905Z",
     "start_time": "2021-08-20T07:57:34.086375Z"
    }
   },
   "outputs": [],
   "source": [
    "def unparse_pseudo_name(method, ctrl, ctrl_id, alt_num, can_empty, cstack):\n",
    "    return \"<%s>\" % encode_name(method, ctrl, ctrl_id, alt_num, can_empty, cstack)\n",
    "\n",
    "def unparse_method_name(mname, my_id):\n",
    "    return '<%s.%s>' % (mname, my_id)\n",
    "\n",
    "def encode_name(method, ctrl, ctrl_id, alt_num, can_empty, stack):\n",
    "    assert ctrl in {'while', 'if'}\n",
    "    return '%s:%s_%s,%s %s#%s' % (method, ctrl, ctrl_id, alt_num, can_empty, json.dumps(stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `check()` function invokes the given subject call with the previously defined `check.py` wrapper, logs and returns the result of the call.\n",
    "\n",
    "**TODO**: What we really want to do, is to generate a new updated tree first after doing the tree surgery. Then, convert this tree to a parenthesized tree by simply doing `tree_to_string` with additional `{}` (or other open/close symbols that does not conflict with the input) attached when joining the nodes. That is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:34.800770Z",
     "start_time": "2021-08-20T07:57:34.792707Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_to_pstr(tree, op_='', _cl=''):\n",
    "    expanded = []\n",
    "    to_expand = [tree]\n",
    "    while to_expand:\n",
    "        (key, children, *_), *to_expand = to_expand\n",
    "        if is_nt(key):\n",
    "            expanded.append(op_)\n",
    "            to_expand = children + [(_cl, [])] + to_expand\n",
    "        else:\n",
    "            assert not children\n",
    "            expanded.append(key)\n",
    "    return ''.join(expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, when using `tree_to_string(my_tree, '{', '}')`, We will get a string that represents how the original string was parsed. For example `1+2+3` may be represented as `{{1+2}+3}`.\n",
    "\n",
    "Next, we need to run the non-parenthesized string resulting from the tree surgery through the program, and collect the resulting tree. Again, convert this tree to the parentesized version, and compare equality.\n",
    "\n",
    "With this, we can ensure that our tree nodes are correctly compatible, and secondly, we can ignore the return code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:35.512708Z",
     "start_time": "2021-08-20T07:57:35.503889Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_inp(inp):\n",
    "    with open(f'subjects/inptxt', 'w+') as f:\n",
    "        print(inp, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:35.548309Z",
     "start_time": "2021-08-20T07:57:35.519471Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def check(o, x, e, ut, module, sa1, sa2):\n",
    "    s = tree_to_str(ut)\n",
    "    if s in EXEC_MAP: return EXEC_MAP[s]\n",
    "    updated_ps = tree_to_pstr(ut, op_='{', _cl='}')\n",
    "    \n",
    "    subprocess.call(['gcc', '-g', module])\n",
    "    #!rm gdb.txt\n",
    "    #!rm gdbtrace\n",
    "    #!rm function_names\n",
    "    \n",
    "    traces = []\n",
    "    try:\n",
    "        save_inp(s)\n",
    "        arg = '\\'py arg0=\"%s\"\\'' % s\n",
    "        argfiles = '\\'py files=\"%s\"\\'' % 'a.out'\n",
    "        !gdb --batch-silent -ex {argfiles} -x miner.py\n",
    "        with open(f'gdbtrace', 'rb') as f:\n",
    "            traces.append((s, jsonpickle.decode(f.read())))\n",
    "\n",
    "        tracker = ScopeTracker(traces[0][0], traces[0][1])\n",
    "        parsed_tree = BinaryScopeTreeMiner(traces[0][0],\n",
    "            tracker.my_assignments.defined_vars(formatted=False))\n",
    "        \n",
    "        parsed_ps = tree_to_pstr(parsed_tree.tree, op_='{', _cl='}')\n",
    "        v = (parsed_ps == updated_ps)\n",
    "    except:\n",
    "        parsed_ps = 'ERROR'\n",
    "        v = False\n",
    "\n",
    "    EXEC_MAP[s] = v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to collect all nodes of a particular kind together. `register_node()` correctly saves specific kinds of nodes separately as copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:36.302515Z",
     "start_time": "2021-08-20T07:57:36.296622Z"
    }
   },
   "outputs": [],
   "source": [
    "def register_node(node, tree, executable, input_file):\n",
    "    # we want to save a copy of the tree so we can modify it later. \n",
    "    node_name = node[0]\n",
    "    template_name = '__BMINER__NODE__'\n",
    "    node[0] = template_name\n",
    "    new_tree = deep_copy(tree)\n",
    "    node[0] = node_name\n",
    "    new_node = get_ref(new_tree, template_name)\n",
    "    new_node[0] = node_name\n",
    "    if node_name not in NODE_REGISTER:\n",
    "        NODE_REGISTER[node_name] = []\n",
    "    new_elt = (new_node, new_tree, executable, input_file,\n",
    "            {'inputstr': tree_to_str(new_tree), 'node':node, 'tree':tree})\n",
    "    NODE_REGISTER[node_name].append(new_elt)\n",
    "    return new_elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:36.320865Z",
     "start_time": "2021-08-20T07:57:36.314435Z"
    }
   },
   "outputs": [],
   "source": [
    "def collect_nodes_single(node, tree, executable, inputfile, seen):\n",
    "    node_name, children, si = node\n",
    "    elt = None\n",
    "    if is_node_method(node):\n",
    "        elt = register_node(node, tree, executable, inputfile)\n",
    "        if node_name in seen:\n",
    "            elt[4]['seen'] = seen[node_name]\n",
    "        else:\n",
    "            seen[node_name] = elt\n",
    "    if len(children) == 1:\n",
    "        collect_nodes_single(children[0], tree, executable, inputfile, seen)\n",
    "    else:\n",
    "        # no longer the single inheritance line.\n",
    "        for child in children:\n",
    "            collect_nodes(child, tree, executable, inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:36.337602Z",
     "start_time": "2021-08-20T07:57:36.328871Z"
    }
   },
   "outputs": [],
   "source": [
    "def collect_nodes(node, tree, executable, inputfile):\n",
    "    node_name, children, si = node\n",
    "    elt = None\n",
    "    if is_node_method(node):\n",
    "        elt = register_node(node, tree, executable, inputfile)\n",
    "    if len(children) == 1:\n",
    "        collect_nodes_single(children[0], tree, executable, inputfile, {node_name: elt})\n",
    "    else:\n",
    "        for child in children:\n",
    "            collect_nodes(child, tree, executable, inputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking to see which methods are swappable, the idea is to choose a small sample set for a given node name, and check the current node against that sample set (swap both ways, and check the validity). The different validity patterns we get are marked as different kinds of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we identify the buckets based on one to one compatibility. Unfortunately, there is a problem here. Essentially, we assume that if `a` is compatible with `b`, and `b` is compatible with `c`, then `a` is compatible with `c`. However, this may not be true in all cases. See the limitations for instances when this assumption is invalidated. At this point, we have several options. The first is to do an $n \\times n$ comparison of all items in the bucket, in which case, we will have the true compatibility but with high computational cost. The next alternative is to choose a node in one bucket, and do the bucketing procedure again with the items in the particular bucket. This produces one more bit of information, and one can continue this prodcedure for larger and larger number of bits. One may also choose a statistical sample of $k$ items in the bucket, and go for a comparison only between $n \\times k$ items.\n",
    "\n",
    "At this point, we choose the fastest option, which gets us a reasonable accuracy. We use a single level classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:37.781410Z",
     "start_time": "2021-08-20T07:57:37.768301Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_buckets(node_name):\n",
    "    all_elts = NODE_REGISTER[node_name]\n",
    "    # remove the duplicate nodes\n",
    "    elts = [e for e in all_elts if 'seen' not in e[4]]\n",
    "    seen_elts = [e for e in all_elts if 'seen' in e[4]]\n",
    "    first, *rest = elts\n",
    "    first[4]['pattern'] = 0\n",
    "    buckets = [first]\n",
    "    for enode in rest:\n",
    "        node0, tree0, executable0, inputfile0, _info0 = enode\n",
    "        a0 = node0, inputfile0, tree0\n",
    "        compatible = None\n",
    "        for bi, bnode in enumerate(buckets):\n",
    "            node1, tree1, executable1, inputfile1, _info1 = bnode\n",
    "            a1 = node1, inputfile1, tree1\n",
    "            result = is_compatible(a0, a1, executable0)\n",
    "            if result:\n",
    "                compatible = bi\n",
    "                enode[4]['pattern'] = bi\n",
    "                break\n",
    "        if compatible is None:\n",
    "            enode[4]['pattern'] = len(buckets)\n",
    "            buckets.append(enode)\n",
    "\n",
    "    for e in seen_elts:\n",
    "        e_seen = e[4]['seen']\n",
    "        e_seen_pattern = e_seen[4]['pattern']\n",
    "        e[4]['pattern'] = e_seen_pattern\n",
    "    return {i: i for i, b in enumerate(buckets)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we identify that a node belongs to a particular pattern identifier, we update all the pseudo-methods belonging to that node. These can be found by simply traversiing the tree until the next method is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:38.483194Z",
     "start_time": "2021-08-20T07:57:38.476143Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_method_stack(node, old_name, new_name):\n",
    "    nname, children, *rest = node\n",
    "    if not (':if_' in nname or ':while_' in nname):\n",
    "        return\n",
    "    method, ctrl, cname, num, can_empty, cstack = parse_pseudo_name(nname)\n",
    "    assert method == old_name, \"%s != %s\" % (method, old_name)\n",
    "    name = unparse_pseudo_name(new_name, ctrl, cname, num, can_empty, cstack)\n",
    "    #assert '?' not in name\n",
    "    node[0] = name\n",
    "    for c in node[1]:\n",
    "        update_method_stack(c, old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:38.501894Z",
     "start_time": "2021-08-20T07:57:38.494470Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_method_name(k_m, my_id):\n",
    "    # fixup k_m with what is in my_id\n",
    "    original = k_m[0]\n",
    "    method, old_id = parse_method_name(original)\n",
    "    name = unparse_method_name(method, my_id)\n",
    "    k_m[0] = name\n",
    "\n",
    "    for c in k_m[1]:\n",
    "        update_method_stack(c, original[1:-1], name[1:-1])\n",
    "\n",
    "    return name, k_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:38.516252Z",
     "start_time": "2021-08-20T07:57:38.508171Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_original_method_names(node_name):\n",
    "    registered_xnodes = NODE_REGISTER[node_name]\n",
    "    for xnode in registered_xnodes:\n",
    "        # name it according to its pattern\n",
    "        nodeX, treeX, executableX, inputfileX, infoX = xnode\n",
    "        pattern = infoX['pattern']\n",
    "        update_method_name(infoX['node'], pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to first collect and register all nodes by their names.\n",
    "Next, we sample N of these, and use the pattern of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:39.293032Z",
     "start_time": "2021-08-20T07:57:39.280522Z"
    }
   },
   "outputs": [],
   "source": [
    "def generalize_method_trees(jtrees, log=False):\n",
    "    my_trees = []\n",
    "    for i, j in enumerate(jtrees):\n",
    "        tree = to_modifiable(j['tree'])  # The tree ds.\n",
    "        executable = j['original']\n",
    "        inputfile = j['arg']\n",
    "        # we skip START\n",
    "        node_name, children, *rest = tree\n",
    "        assert node_name == START_SYMBOL\n",
    "        for child in children:\n",
    "            collect_nodes(tree, tree, executable, inputfile)\n",
    "        my_trees.append({'tree':tree, 'original': executable, 'arg': inputfile})\n",
    "        \n",
    "    for k in NODE_REGISTER:\n",
    "        identify_buckets(k)\n",
    "    \n",
    "    # finally, update the original names.\n",
    "    for k in NODE_REGISTER:\n",
    "        if k == START_SYMBOL: continue\n",
    "        update_original_method_names(k)\n",
    "    return my_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Debug Adapter Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAP Debug Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:40.769942Z",
     "start_time": "2021-08-20T07:57:40.764453Z"
    }
   },
   "outputs": [],
   "source": [
    "class IDebugSession:\n",
    "    def attach(self, request):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def launchRequest(self, request):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def initializeRequest(self, request):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:40.793848Z",
     "start_time": "2021-08-20T07:57:40.782394Z"
    }
   },
   "outputs": [],
   "source": [
    "class DAPDebugSession(IDebugSession):\n",
    "    def __init__(self):\n",
    "        self.d = None\n",
    "\n",
    "    def launchRequest(self, request):\n",
    "        arguments = request['arguments']\n",
    "        debugee = arguments['debugee']\n",
    "        arg = arguments['arg']\n",
    "        kwargs = arguments['kwarg']\n",
    "\n",
    "        self.d = BinaryDebugger(gdb, debugee, arg, **kwargs)\n",
    "        self.d.event_loop()\n",
    "        trace = self.d.tracer.trace\n",
    "        return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:40.803291Z",
     "start_time": "2021-08-20T07:57:40.798426Z"
    }
   },
   "outputs": [],
   "source": [
    "class DAPDebugSession(DAPDebugSession):\n",
    "    def initializeRequest(self, request):\n",
    "        payload = {\n",
    "            'supportsLogPoints': True,\n",
    "            'supportsSetVariable': True\n",
    "        }\n",
    "        arguments = request['arguments']\n",
    "        self.supportsRunInTerminalRequest = arguments[\n",
    "            'supportsRunInTerminalRequest']\n",
    "        return payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.595300Z",
     "start_time": "2021-08-20T07:57:41.588163Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import socket\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.618167Z",
     "start_time": "2021-08-20T07:57:41.610149Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugServer:\n",
    "    def __init__(self, host, port):\n",
    "        self.EVENT = {\n",
    "            'type': 'event',\n",
    "            'body': {},\n",
    "            'event': '',\n",
    "            'seq': 0,\n",
    "            'type': ''\n",
    "        }\n",
    "        self.RESPONSE = {\n",
    "            'type': 'response',\n",
    "            'success': False,\n",
    "            'seq': 0,\n",
    "            'request_seq': 0,\n",
    "            'body': {},\n",
    "            'command': '',\n",
    "            'message': ''\n",
    "        }\n",
    "        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        self.socket.bind((host, port))\n",
    "        self.socket.listen(20)\n",
    "        self.debugSession = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.641919Z",
     "start_time": "2021-08-20T07:57:41.633422Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugServer(BinaryDebugServer):\n",
    "    def sendResponse(self, conn, message):\n",
    "        s_msg = json.dumps(message)\n",
    "        response = 'Content-Length: {0}\\r\\n\\r\\n{1}'.format(len(s_msg), s_msg)\n",
    "        response = bytes(response, 'utf-8')\n",
    "        conn.send(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.666867Z",
     "start_time": "2021-08-20T07:57:41.650495Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugServer(BinaryDebugServer):\n",
    "    def parse_all_messages(self, msg_str):\n",
    "        split_delimiter = 'Content-Length: '\n",
    "        msg_list = msg_str.split(split_delimiter)\n",
    "        if (msg_list[0] == ''):\n",
    "            msg_list = msg_list[1:]\n",
    "        parsed_msg_list = [msg.split('\\r\\n\\r\\n') for msg in msg_list]\n",
    "        for index in range(len(parsed_msg_list)):\n",
    "            parsed_msg_list[index][\n",
    "                0] = split_delimiter + parsed_msg_list[index][0]\n",
    "        return parsed_msg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.695957Z",
     "start_time": "2021-08-20T07:57:41.670234Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryDebugServer(BinaryDebugServer):\n",
    "    def server_loop(self):\n",
    "        while True:\n",
    "            conn, _ = self.socket.accept()\n",
    "            data = conn.recv(1024).decode()\n",
    "            if not data:\n",
    "                continue\n",
    "\n",
    "            self.debugSession = DAPDebugSession()\n",
    "            msgs = self.parse_all_messages(data)\n",
    "            payload = msgs[0][1]\n",
    "            payload = json.loads(payload)\n",
    "\n",
    "            if payload['command'] == 'initialize':\n",
    "                body = self.debugSession.initializeRequest(payload)\n",
    "                res = self.RESPONSE\n",
    "                res['body'] = body\n",
    "\n",
    "                res['command'] = 'initialize'\n",
    "                res['success'] = 'True'\n",
    "                self.sendResponse(conn, res)\n",
    "\n",
    "                res1 = self.EVENT\n",
    "                res1['event'] = 'initialized'\n",
    "                self.sendResponse(conn, res1)\n",
    "\n",
    "            elif payload['command'] == 'launch':\n",
    "                trace = self.debugSession.launchRequest(payload)\n",
    "                fileName = 'gdbtrace'\n",
    "\n",
    "                with open(fileName, 'w+') as f:\n",
    "                    print(jsonpickle.encode(trace), file=f)\n",
    "                self.sendResponse(conn, fileName)\n",
    "\n",
    "            elif payload['command'] == 'functionNames':\n",
    "                fn_names = self.debugSession.functionNameRequest(payload)\n",
    "                with open('function_names', 'w+') as f:\n",
    "                    print(jsonpickle.encode(fn_names), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:41.806798Z",
     "start_time": "2021-08-20T07:57:41.701208Z"
    }
   },
   "outputs": [],
   "source": [
    "server_head = \"\"\"\\\n",
    "import sys\n",
    "sys.path.extend([%s])\n",
    "sys.path.append('.')\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot._IP_REGISTERED = True # Hack\n",
    "from fuzzingbook import fuzzingbook_utils\n",
    "from fuzzingbook.GrammarMiner import GrammarMiner, Context, Tracer, Coverage, ScopedGrammarMiner, AssignmentVars, readable, flatten\n",
    "import jsonpickle\n",
    "import os, subprocess\n",
    "import gdb\n",
    "import re\n",
    "import json\n",
    "import socket\n",
    "\"\"\" % (', '.join(\"'%s'\" % str(i) for i in sys.path if i))\n",
    "debugger_src = fuzzingbook_utils.extract_class_definition(Debugger)\n",
    "context_src = fuzzingbook_utils.extract_class_definition(GDBContext)\n",
    "gdbtracer_src = fuzzingbook_utils.extract_class_definition(GDBTracer)\n",
    "varextractor_src = fuzzingbook_utils.extract_class_definition(VarExtractor)\n",
    "gdbdebugger_src = fuzzingbook_utils.extract_class_definition(GDBDebugger)\n",
    "\n",
    "instr_src = fuzzingbook_utils.extract_class_definition(Instruction)\n",
    "frame_src = fuzzingbook_utils.extract_class_definition(Frame)\n",
    "binary_cxt_src = fuzzingbook_utils.extract_class_definition(BinaryContext)\n",
    "b_extractor_src = fuzzingbook_utils.extract_class_definition(BinaryVarExtractor)\n",
    "binary_tracer_src = fuzzingbook_utils.extract_class_definition(BinaryTracer)\n",
    "stripped_debugger_src = fuzzingbook_utils.extract_class_definition(\n",
    "    BinaryDebugger)\n",
    "\n",
    "IDebugSession_src = fuzzingbook_utils.extract_class_definition(IDebugSession)\n",
    "DAPDebugSession_src = fuzzingbook_utils.extract_class_definition(DAPDebugSession)\n",
    "BinaryDebugServer_src = fuzzingbook_utils.extract_class_definition(BinaryDebugServer)\n",
    "\n",
    "helper = \"\"\"\n",
    "def recover_fnames(inp, debugee):\n",
    "    fn_dict = {}\n",
    "    fn_names = []\n",
    "    gdb.execute(\"set args '%s'\" % inp)\n",
    "    gdb.execute(\"file %s\" % debugee)\n",
    "    gdb.execute('set confirm off')\n",
    "\n",
    "    all_defined_functions = gdb.execute('info functions', to_string=True)\n",
    "    lines = all_defined_functions.splitlines()[3:]\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            line = line.split()\n",
    "            line = line[2:]\n",
    "            if '(' in line[0]:\n",
    "                l = line[0].split('(')\n",
    "                fn_names.append(l[0].strip('*'))\n",
    "            else:\n",
    "                l = line[1].split('(')\n",
    "                fn_names.append(l[0].strip('*'))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    gdb.execute('run')\n",
    "    for k in fn_names:\n",
    "        try:\n",
    "            s = gdb.execute('info address %s' % k, to_string=True)\n",
    "            addr = s.split()[-1].strip('.')\n",
    "            fn_dict[addr] = k\n",
    "        except gdb.error:\n",
    "            continue\n",
    "    \n",
    "    return fn_dict\n",
    "\"\"\"\n",
    "\n",
    "server_tail = \"\"\"\n",
    "b = BinaryDebugServer('', 8541)\n",
    "b.server_loop()\n",
    "\"\"\"\n",
    "server_src = '\\n'.join([\n",
    "    server_head, debugger_src, context_src, gdbtracer_src, varextractor_src,\n",
    "    gdbdebugger_src, global_declarations, helper_methods, instr_src, frame_src, binary_cxt_src,b_extractor_src, binary_tracer_src,\n",
    "    stripped_debugger_src, helper, IDebugSession_src, DAPDebugSession_src, BinaryDebugServer_src, server_tail\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: This file can should be executed on a separate terminal using the command \n",
    "`gdb --batch-silent -x dapServer.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:42.508857Z",
     "start_time": "2021-08-20T07:57:42.501424Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('dapServer.py', 'w+') as f:\n",
    "    print(server_src, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.214426Z",
     "start_time": "2021-08-20T07:57:44.211266Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint                                       \n",
    "import time   \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.231445Z",
     "start_time": "2021-08-20T07:57:44.223593Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass:\n",
    "    def __init__(self, hostname='', port=8541, timeout=5, sock=None):\n",
    "        self.msg_id = random.randint(1,500)\n",
    "        self.connection_no = 1\n",
    "        self.mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.mysocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        self.port = port\n",
    "        self.hostname = hostname\n",
    "        self.mysocket.settimeout(timeout)\n",
    "        self.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.248880Z",
     "start_time": "2021-08-20T07:57:44.242729Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def connect(self):\n",
    "        self.mysocket.connect((self.hostname, self.port))\n",
    "        self.connection_no += 1\n",
    "        time.sleep(1)\n",
    "        #the debug server responds to successful connection\n",
    "        self.recvMessage(\"connection no {} \".format(self.connection_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.263109Z",
     "start_time": "2021-08-20T07:57:44.251443Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def parse_all_messages(self, msg_bytes):\n",
    "        msg_str = msg_bytes.decode('utf-8')\n",
    "        split_delimiter = 'Content-Length: '\n",
    "        msg_list = msg_str.split(split_delimiter)\n",
    "        if (msg_list[0] == ''):\n",
    "            msg_list = msg_list[1:]\n",
    "        parsed_msg_list = [msg.split('\\r\\n\\r\\n') for msg in msg_list]\n",
    "        for index in range(len(parsed_msg_list)):\n",
    "            parsed_msg_list[index][\n",
    "                0] = split_delimiter + parsed_msg_list[index][0]\n",
    "        return parsed_msg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.276419Z",
     "start_time": "2021-08-20T07:57:44.266712Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def recvMessage(self, func_name):\n",
    "        sock = self.mysocket\n",
    "        try:\n",
    "            recv_data = sock.recv(1024 * 1024)\n",
    "        except socket.timeout:\n",
    "            print(\"Timeout. Nothing was received at\", func_name)\n",
    "            return\n",
    "        list_of_msgs = self.parse_all_messages(recv_data)\n",
    "        return list_of_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.291014Z",
     "start_time": "2021-08-20T07:57:44.281688Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def sendMessage(self, msg):\n",
    "        sock = self.mysocket\n",
    "        s_msg = json.dumps(msg)\n",
    "        data = 'Content-Length: {0}\\r\\n\\r\\n{1}'.format(len(s_msg), s_msg)\n",
    "        data = bytes(data, 'utf-8')\n",
    "        sock.send(data)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.300126Z",
     "start_time": "2021-08-20T07:57:44.294714Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def doRequest(self, msg):\n",
    "        this_id = self.msg_id\n",
    "        self.msg_id += 1\n",
    "        msg['seq'] = this_id\n",
    "        msg['type'] = 'request'\n",
    "        self.sendMessage(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:44.315709Z",
     "start_time": "2021-08-20T07:57:44.309693Z"
    }
   },
   "outputs": [],
   "source": [
    "class connectionClass(connectionClass):\n",
    "    def close_connection(self):\n",
    "        self.recvMessage(\"Cleanup\")\n",
    "        self.mysocket.close()\n",
    "\n",
    "    def reset_connection(self):\n",
    "        self.close_connection()\n",
    "        self.mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:45.159999Z",
     "start_time": "2021-08-20T07:57:45.153337Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryClient:\n",
    "    def __init__(self, hostname='', port=8541, timeout=5):\n",
    "        self.connection = connectionClass(hostname, port, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:45.176275Z",
     "start_time": "2021-08-20T07:57:45.167503Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryClient(BinaryClient):\n",
    "    def launch(self, seed, dbgfile, **kwargs):\n",
    "        self.connection.doRequest({\n",
    "            'command': 'launch',\n",
    "            'type': 'request',\n",
    "            'arguments': {\n",
    "                'noDebug': 'False',\n",
    "                '__restart': '',\n",
    "                'debugee': dbgfile,\n",
    "                'arg': seed,\n",
    "                'kwarg': kwargs\n",
    "            },\n",
    "        })\n",
    "        return self.connection.recvMessage(\"launch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:45.194936Z",
     "start_time": "2021-08-20T07:57:45.184295Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryClient(BinaryClient):\n",
    "    def initialize(self, clientID=None):\n",
    "        if clientID is None:\n",
    "            clientID = self.__class__.__name__\n",
    "        self.connection.doRequest({\n",
    "            'command': 'initialize',\n",
    "            'arguments': {\n",
    "                'adapterID': 'pydevd',\n",
    "                'clientID': clientID,\n",
    "            },\n",
    "        })\n",
    "        self.connection.recvMessage(\"initialize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:46.062820Z",
     "start_time": "2021-08-20T07:57:46.056837Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_tree(derivation_tree):\n",
    "    node, children, *rest = derivation_tree\n",
    "    return tuple([node, [fit_tree(c) for c in children], *rest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:46.077637Z",
     "start_time": "2021-08-20T07:57:46.071183Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "def zoom(v, zoom=True):\n",
    "    # return v directly if you do not want to zoom out.\n",
    "    if zoom:\n",
    "        return Image(v.render(format='png'))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We updated the method `update_grammar` in order to make use method generalization on the mined trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:46.992198Z",
     "start_time": "2021-08-20T07:57:46.981787Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryScopedGrammarMiner(BinaryScopedGrammarMiner):\n",
    "    def update_grammar(self, inputstr, trace, executable):\n",
    "        at = self.create_tracker(inputstr, trace)\n",
    "        dt = self.create_tree_miner(inputstr, at.my_assignments.defined_vars(formatted=False))\n",
    "        \n",
    "        tree = [format_mined_tree(dt.tree, executable, inputstr)]\n",
    "        generalized_tree = generalize_method_trees(tree)\n",
    "        new_tree = fit_tree(tuple(generalized_tree[0]['tree']))\n",
    "        \n",
    "        #v = display_tree(new_tree)\n",
    "        self.add_tree(new_tree)\n",
    "        #zoom(v)\n",
    "        return self.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:47.016244Z",
     "start_time": "2021-08-20T07:57:47.011333Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from fuzzingbook.GrammarMiner import display_tree, lr_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:47.042204Z",
     "start_time": "2021-08-20T07:57:47.030741Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryScopedGrammarMiner(BinaryScopedGrammarMiner):\n",
    "    def add_tree(self, t):\n",
    "        t_grammar = self.tree_to_grammar(t)\n",
    "        self.grammar = {\n",
    "            key: self.grammar.get(key, []) + t_grammar.get(key, [])\n",
    "            for key in itertools.chain(self.grammar.keys(), t_grammar.keys())\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:48.990144Z",
     "start_time": "2021-08-20T07:57:48.978820Z"
    }
   },
   "outputs": [],
   "source": [
    "def recover_grammar(inps, src, executable):\n",
    "    traces = []\n",
    "    miner = BinaryScopedGrammarMiner()\n",
    "    \n",
    "    for c, inp in enumerate(inps):\n",
    "        save_inp(inp)\n",
    "        arg = '\\'py arg0=\"%s\"\\'' % inp\n",
    "        argfiles = '\\'py files=\"%s\"\\'' % src\n",
    "        print(arg)\n",
    "        !gdb --batch-silent -ex {argfiles} -x miner.py\n",
    "        with open(f'gdbtrace', 'rb') as f:\n",
    "            traces.append((inp, jsonpickle.decode(f.read())))\n",
    "        #!cp gdbtrace gdbtrace.{c} \n",
    "    \n",
    "    \n",
    "    for inp, trace in traces:\n",
    "        reset_generalizer()\n",
    "        miner.update_grammar(inp, trace, executable)\n",
    "    return (readable(miner.clean_grammar()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:49.869468Z",
     "start_time": "2021-08-20T07:57:49.851346Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "tracer_head = \"\"\"\\\n",
    "import sys\n",
    "sys.path.extend([%s])\n",
    "sys.path.append('.')\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot._IP_REGISTERED = True # Hack\n",
    "from fuzzingbook import fuzzingbook_utils\n",
    "from fuzzingbook.GrammarMiner import GrammarMiner, Context, Tracer, Coverage, ScopedGrammarMiner, AssignmentVars, readable, flatten\n",
    "import jsonpickle\n",
    "import os, subprocess\n",
    "import gdb\n",
    "import re\n",
    "import json                                                                     \n",
    "import socket                                                                   \n",
    "from pprint import pprint                                       \n",
    "import time   \n",
    "import random\n",
    "\"\"\" % (', '.join(\"'%s'\" % str(i) for i in sys.path if i))\n",
    "connection_src = fuzzingbook_utils.extract_class_definition(connectionClass)\n",
    "client_src = fuzzingbook_utils.extract_class_definition(BinaryClient)\n",
    "\n",
    "tracer_tail = \"\"\"\n",
    "file_name = 'gdbtrace'\n",
    "binary = 'a.out'\n",
    "def recover_fnames(inp, debugee):\n",
    "    fn_dict = {}\n",
    "    fn_names = []\n",
    "    gdb.execute(\"set args '%s'\" % inp)\n",
    "    gdb.execute(\"file %s\" % debugee)\n",
    "    gdb.execute('set confirm off')\n",
    "\n",
    "    all_defined_functions = gdb.execute('info functions', to_string=True)\n",
    "    lines = all_defined_functions.splitlines()[3:]\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            line = line.split()\n",
    "            line = line[2:]\n",
    "            if '(' in line[0]:\n",
    "                l = line[0].split('(')\n",
    "                fn_names.append(l[0].strip('*'))\n",
    "            else:\n",
    "                l = line[1].split('(')\n",
    "                fn_names.append(l[0].strip('*'))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    gdb.execute('run')\n",
    "    for k in fn_names:\n",
    "        try:\n",
    "            s = gdb.execute('info address %s' % k, to_string=True)\n",
    "            addr = s.split()[-1].strip('.')\n",
    "            fn_dict[addr] = k\n",
    "        except gdb.error:\n",
    "            continue\n",
    "    \n",
    "    with open('function_names', 'w+') as f:\n",
    "        print(jsonpickle.encode(fn_dict), file=f)\n",
    "\n",
    "def request_loop(gdb, f, inp, **kwargs):\n",
    "    client = BinaryClient()\n",
    "    trace = client.launch(inp, f, **kwargs)\n",
    "    client.connection.close_connection()\n",
    "    \n",
    "def recover_trace(f, inp, **kwargs):\n",
    "    request_loop(gdb, f, inp, **kwargs)\n",
    "\n",
    "arg_0 = None\n",
    "with open(f'subjects/inptxt', 'r+') as f:\n",
    "    arg_0 = f.read().replace('\\\\n', '')\n",
    "\n",
    "if not os.path.exists('function_names'):\n",
    "    recover_fnames(str(arg_0), binary)\n",
    "\n",
    "subprocess.call(['strip', '-s', binary])\n",
    "recover_trace(binary, str(arg_0), files=[binary])\n",
    "\"\"\"\n",
    "tracer_src = '\\n'.join([\n",
    "    tracer_head, connection_src, client_src, tracer_tail\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:57:49.880396Z",
     "start_time": "2021-08-20T07:57:49.873794Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('miner.py', 'w+') as f:\n",
    "    print(tracer_src, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CGIDecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:59:16.667954Z",
     "start_time": "2021-08-20T07:59:16.661181Z"
    }
   },
   "outputs": [],
   "source": [
    "cgidecode_samples = [\n",
    "    'Hello%2c+world%21',\n",
    "    'Send+mail+to+me%40fuzzingbook.org',\n",
    "    'name=Fred&class=101&math=2+%2B+2+%3D+4&',\n",
    "    'name=Fred&status=good&status=happy&',\n",
    "    'http://target/getdata.php?data=%3cscript%20src=%22http%3a%2f%2f',\n",
    "    'www.badplace.com%2fnasty.js%22%3e%3c%2fscript%3e',\n",
    "    'http://target/login.asp?userid=bob%27%3b%20update%20logintable%20set%20passwd%3d%270wn3d%27%3b--%00',\n",
    "    'Colon%20%3A%20Hash%20%23%20Percent%20%25',\n",
    "    'O%21nP%22BG%23JI%24Tw%25mJ%26bB%27xX%28zy%29Aj%2aZ',\n",
    "    'E%2bNp%2cRP%2dVN%2eyV%2ftW%2AIJ%2BAe%2CkM%2DKf%2EB',\n",
    "    'W%2FAo%3azF%3blw%3ctY%3dqy%3eLm%3fCS%3AyB%3BHq%3Ck',\n",
    "    'y%3DZM%3EVH%3FRx%40gG%5bhh%5cjn%5dOD%5eDR%5fcu%5Bm',\n",
    "    'b%5CJm%5Drl%5Ezn%5FKe%60hQ%7bBj%7chf%7dmB%7eyc%7Bp',\n",
    "    'w%7CWd%7DCG%7Ec',\n",
    "    'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
    "    '1234567890',\n",
    "    '-./_~'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:59:19.073978Z",
     "start_time": "2021-08-20T07:59:18.433154Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'gdb.txt': No such file or directory\n",
      "rm: cannot remove 'gdbtrace': No such file or directory\n",
      "rm: cannot remove 'function_names': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!gcc -g -o a.out subjects/cgi_decode.c\n",
    "!rm gdb.txt\n",
    "!rm gdbtrace\n",
    "!rm function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:25:52.436946Z",
     "start_time": "2021-08-20T07:59:22.030810Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'py arg0=\"Hello%2c+world%21\"'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<start>': ['<cgi_decode@a_55:var_23.0>'],\n",
       " '<cgi_decode@a_55:var_23.0>': ['<cgi_decode@a_57:var_25.0><cgi_decode@a_55:var_23.1>'],\n",
       " '<cgi_decode@a_57:var_25.0>': ['H'],\n",
       " '<cgi_decode@a_55:var_23.1>': ['<cgi_decode@a_57:var_25.1><cgi_decode@a_55:var_23.2>'],\n",
       " '<cgi_decode@a_57:var_25.1>': ['e'],\n",
       " '<cgi_decode@a_55:var_23.2>': ['<cgi_decode@a_57:var_25.2><cgi_decode@a_55:var_23.3>'],\n",
       " '<cgi_decode@a_57:var_25.2>': ['l'],\n",
       " '<cgi_decode@a_55:var_23.3>': ['l<cgi_decode@a_55:var_23.4>'],\n",
       " '<cgi_decode@a_55:var_23.4>': ['<cgi_decode@a_57:var_25.3><cgi_decode@a_48:var_18.5>'],\n",
       " '<cgi_decode@a_57:var_25.3>': ['o'],\n",
       " '<cgi_decode@a_48:var_18.5>': ['%<cgi_decode@a_60:var_26.0>'],\n",
       " '<cgi_decode@a_60:var_26.0>': ['2<cgi_decode@a_65:var_30.0>'],\n",
       " '<cgi_decode@a_65:var_30.0>': ['c<cgi_decode@a_44:var_16.6>'],\n",
       " '<cgi_decode@a_44:var_16.6>': ['+<cgi_decode@a_55:var_23.5>'],\n",
       " '<cgi_decode@a_55:var_23.5>': ['<cgi_decode@a_57:var_25.4><cgi_decode@a_55:var_23.6>'],\n",
       " '<cgi_decode@a_57:var_25.4>': ['w'],\n",
       " '<cgi_decode@a_55:var_23.6>': ['o<cgi_decode@a_55:var_23.7>'],\n",
       " '<cgi_decode@a_55:var_23.7>': ['<cgi_decode@a_57:var_25.5><cgi_decode@a_55:var_23.8>'],\n",
       " '<cgi_decode@a_57:var_25.5>': ['r'],\n",
       " '<cgi_decode@a_55:var_23.8>': ['l<cgi_decode@a_55:var_23.9>'],\n",
       " '<cgi_decode@a_55:var_23.9>': ['<cgi_decode@a_57:var_25.6><cgi_decode@a_48:var_18.11>'],\n",
       " '<cgi_decode@a_57:var_25.6>': ['d'],\n",
       " '<cgi_decode@a_48:var_18.11>': ['%<cgi_decode@a_60:var_26.1>'],\n",
       " '<cgi_decode@a_60:var_26.1>': ['2<cgi_decode@a_65:var_30.1>'],\n",
       " '<cgi_decode@a_65:var_30.1>': ['1']}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = recover_grammar([cgidecode_samples[0]], 'a.out', 'subjects/cgi_decode.c')\n",
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URLParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:28:38.190337Z",
     "start_time": "2021-08-20T08:28:38.178569Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import URLS, START_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:28:40.607398Z",
     "start_time": "2021-08-20T08:28:39.937769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcc -g -o a.out subjects/url_parse.c\n",
    "!rm gdb.txt\n",
    "!rm gdbtrace\n",
    "!rm function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:29:35.477668Z",
     "start_time": "2021-08-20T08:28:52.372134Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'py arg0=\"http://user:pass@www.google.com:80/?q=path#ref\"'\n",
      "'py arg0=\"https://www.cispa.saarland:80/\"'\n",
      "'py arg0=\"http://www.fuzzingbook.org/#News\"'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<start>': ['<parse_url@a_131:var_654.0>'],\n",
       " '<parse_url@a_131:var_654.0>': ['<parse_url@a_88:var_669.0><parse_url@a_132:var_655.0><parse_url@a_145:var_41.0>'],\n",
       " '<parse_url@a_88:var_669.0>': ['<parse_url@a_164:var_679.0>',\n",
       "  '<parse_url@a_173:var_694.0>'],\n",
       " '<parse_url@a_164:var_679.0>': ['http'],\n",
       " '<parse_url@a_132:var_655.0>': ['://', ':<parse_url@a_85:var_45.0>/'],\n",
       " '<parse_url@a_145:var_41.0>': ['<parse_url@a_158:var_675.0>/',\n",
       "  '<parse_url@a_158:var_675.0><parse_url@a_85:var_45.0>'],\n",
       " '<parse_url@a_158:var_675.0>': ['<parse_url@a_176:var_696.0>',\n",
       "  'user:pass<parse_url@a_165:var_680.0>'],\n",
       " '<parse_url@a_165:var_680.0>': ['@www.google.com:80'],\n",
       " '<parse_url@a_85:var_45.0>': ['/<parse_url@a_152:var_52.0>', '/'],\n",
       " '<parse_url@a_152:var_52.0>': ['<parse_url@a_154:var_672.0>',\n",
       "  '?q=path<parse_url@a_154:var_672.0>'],\n",
       " '<parse_url@a_154:var_672.0>': ['#ref', '#News'],\n",
       " '<parse_url@a_173:var_694.0>': ['<parse_url@a_186:var_704.0>', 'http'],\n",
       " '<parse_url@a_186:var_704.0>': ['https'],\n",
       " '<parse_url@a_176:var_696.0>': ['www.fuzzingbook.org',\n",
       "  'www.cispa.saarland<parse_url@a_180:var_698.0>'],\n",
       " '<parse_url@a_180:var_698.0>': [':<parse_url@a_184:var_702.0>'],\n",
       " '<parse_url@a_184:var_702.0>': ['80']}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = recover_grammar(URLS, 'a.out', 'subjects/url_parse.c')\n",
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T10:45:19.559799Z",
     "start_time": "2021-08-12T10:45:19.551808Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import GrammarFuzzer, URLS_X, VEHICLES\n",
    "x = GrammarFuzzer(grammar)\n",
    "\n",
    "for i in range(10):\n",
    "    print(x.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:44:38.220808Z",
     "start_time": "2021-08-20T08:44:38.217361Z"
    }
   },
   "outputs": [],
   "source": [
    "json_samples = [i.strip().replace('\\n', ' ') for i in [\n",
    "'''\n",
    "{\"value\": \"New\", \"onclick\": \"CreateNewDoc()\"}\n",
    "''']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:44:40.825136Z",
     "start_time": "2021-08-20T08:44:40.231039Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcc -g -o a.out subjects/json.c\n",
    "#!rm a.out\n",
    "!rm gdb.txt\n",
    "!rm gdbtrace\n",
    "!rm function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:52:45.499236Z",
     "start_time": "2021-08-20T08:44:42.257575Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'py arg0=\"{\"value\": \"New\", \"onclick\": \"CreateNewDoc()\"}\"'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<start>': ['<json_parse_value@a_107:var_92.0>'],\n",
       " '<json_parse_value@a_107:var_92.0>': ['{<skip_whitespace@a_39:var_39.1>'],\n",
       " '<skip_whitespace@a_39:var_39.1>': ['<skip_whitespace@a_62:var_58.1>'],\n",
       " '<skip_whitespace@a_62:var_58.1>': ['<skip_whitespace@a_39:var_39.1>',\n",
       "  '<json_parse_value@a_174:var_199.0>'],\n",
       " '<json_parse_value@a_174:var_199.0>': ['\"<json_parse_value@a_184:var_208.0>'],\n",
       " '<json_parse_value@a_184:var_208.0>': ['<skip_whitespace@a_87:var_7734.0><json_parse_value@a_213:var_234.0>'],\n",
       " '<skip_whitespace@a_87:var_7734.0>': ['value'],\n",
       " '<json_parse_value@a_213:var_234.0>': ['\"<json_parse_value@a_216:var_237.0>'],\n",
       " '<json_parse_value@a_216:var_237.0>': [':<skip_whitespace@a_252:var_305.0>'],\n",
       " '<skip_whitespace@a_252:var_305.0>': [' <json_parse_value@a_174:var_199.1>'],\n",
       " '<json_parse_value@a_174:var_199.1>': ['\"<json_parse_value@a_184:var_208.1>'],\n",
       " '<json_parse_value@a_184:var_208.1>': ['<skip_whitespace@a_87:var_7872.0><json_parse_value@a_213:var_234.1>'],\n",
       " '<skip_whitespace@a_87:var_7872.0>': ['New'],\n",
       " '<json_parse_value@a_213:var_234.1>': ['\"<json_parse_value@a_216:var_237.1>'],\n",
       " '<json_parse_value@a_216:var_237.1>': [', <skip_whitespace@a_62:var_58.4>'],\n",
       " '<skip_whitespace@a_62:var_58.4>': ['\"<skip_whitespace@a_87:var_7920.0>\": \"Create<isspace_@a_82:var_7878.0>Doc()<json_parse_value@a_213:var_234.2>'],\n",
       " '<skip_whitespace@a_87:var_7920.0>': ['onclick'],\n",
       " '<isspace_@a_82:var_7878.0>': ['New'],\n",
       " '<json_parse_value@a_213:var_234.2>': ['\"<json_parse_value@a_216:var_237.2>'],\n",
       " '<json_parse_value@a_216:var_237.2>': ['}']}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_grammar = recover_grammar([json_samples[0]], 'a.out', 'subjects/json.c')\n",
    "json_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T16:59:30.906161Z",
     "start_time": "2021-08-11T16:59:30.895897Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import GrammarFuzzer, URLS_X\n",
    "x = GrammarFuzzer(json_grammar)\n",
    "\n",
    "for i in range(10):\n",
    "    print(x.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:53:44.206173Z",
     "start_time": "2021-08-20T08:53:44.198960Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzingbook.GrammarMiner import VEHICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T08:53:49.046341Z",
     "start_time": "2021-08-20T08:53:48.454223Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'gdb.txt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!gcc -g subjects/csvparser.c\n",
    "!rm gdb.txt\n",
    "!rm gdbtrace\n",
    "!rm function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T10:11:06.459581Z",
     "start_time": "2021-08-20T09:03:26.765209Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'py arg0=\"1997,van,Ford,E350\"'\n",
      "TITLE: 1997\n",
      "TITLE: van\n",
      "TITLE: Ford\n",
      "TITLE: E350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<start>': ['<_csvparser_getrow@a_152:var_119.0>'],\n",
       " '<_csvparser_getrow@a_152:var_119.0>': ['<_csvparser_getrow@a_190:var_135.0><_csvparser_getrow@a_152:var_119.1>'],\n",
       " '<_csvparser_getrow@a_190:var_135.0>': ['1'],\n",
       " '<_csvparser_getrow@a_152:var_119.1>': ['<_csvparser_getrow@a_193:var_138.1><_csvparser_getrow@a_152:var_119.2>'],\n",
       " '<_csvparser_getrow@a_193:var_138.1>': ['9'],\n",
       " '<_csvparser_getrow@a_152:var_119.2>': ['9<_csvparser_getrow@a_152:var_119.3>'],\n",
       " '<_csvparser_getrow@a_152:var_119.3>': ['<_csvparser_getrow@a_193:var_138.2><_csvparser_getrow@a_152:var_119.4>'],\n",
       " '<_csvparser_getrow@a_193:var_138.2>': ['7'],\n",
       " '<_csvparser_getrow@a_152:var_119.4>': [',<_csvparser_getrow@a_152:var_119.5>'],\n",
       " '<_csvparser_getrow@a_152:var_119.5>': ['<_csvparser_getrow@a_190:var_135.1><_csvparser_getrow@a_152:var_119.6>'],\n",
       " '<_csvparser_getrow@a_190:var_135.1>': ['v'],\n",
       " '<_csvparser_getrow@a_152:var_119.6>': ['<_csvparser_getrow@a_193:var_138.4><_csvparser_getrow@a_152:var_119.7>'],\n",
       " '<_csvparser_getrow@a_193:var_138.4>': ['a'],\n",
       " '<_csvparser_getrow@a_152:var_119.7>': ['<_csvparser_getrow@a_193:var_138.5><_csvparser_getrow@a_152:var_119.8>'],\n",
       " '<_csvparser_getrow@a_193:var_138.5>': ['n'],\n",
       " '<_csvparser_getrow@a_152:var_119.8>': [',<_csvparser_getrow@a_152:var_119.9>'],\n",
       " '<_csvparser_getrow@a_152:var_119.9>': ['<_csvparser_getrow@a_190:var_135.2><_csvparser_getrow@a_152:var_119.10>'],\n",
       " '<_csvparser_getrow@a_190:var_135.2>': ['F'],\n",
       " '<_csvparser_getrow@a_152:var_119.10>': ['<_csvparser_getrow@a_193:var_138.7><_csvparser_getrow@a_152:var_119.11>'],\n",
       " '<_csvparser_getrow@a_193:var_138.7>': ['o'],\n",
       " '<_csvparser_getrow@a_152:var_119.11>': ['<_csvparser_getrow@a_193:var_138.8><_csvparser_getrow@a_152:var_119.12>'],\n",
       " '<_csvparser_getrow@a_193:var_138.8>': ['r'],\n",
       " '<_csvparser_getrow@a_152:var_119.12>': ['<_csvparser_getrow@a_193:var_138.9><_csvparser_getrow@a_152:var_119.13>'],\n",
       " '<_csvparser_getrow@a_193:var_138.9>': ['d'],\n",
       " '<_csvparser_getrow@a_152:var_119.13>': [',<_csvparser_getrow@a_152:var_119.14>'],\n",
       " '<_csvparser_getrow@a_152:var_119.14>': ['<_csvparser_getrow@a_190:var_135.3><_csvparser_getrow@a_152:var_119.15>'],\n",
       " '<_csvparser_getrow@a_190:var_135.3>': ['E'],\n",
       " '<_csvparser_getrow@a_152:var_119.15>': ['<_csvparser_getrow@a_193:var_138.11><_csvparser_getrow@a_152:var_119.16>'],\n",
       " '<_csvparser_getrow@a_193:var_138.11>': ['3'],\n",
       " '<_csvparser_getrow@a_152:var_119.16>': ['<_csvparser_getrow@a_193:var_138.12><_csvparser_getrow@a_193:var_138.13>'],\n",
       " '<_csvparser_getrow@a_193:var_138.12>': ['5'],\n",
       " '<_csvparser_getrow@a_193:var_138.13>': ['0']}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_grammar = recover_grammar([VEHICLES[0]], 'a.out', 'subjects/csv.c')\n",
    "csv_grammar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "828px",
    "left": "25px",
    "top": "150px",
    "width": "500.122px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
